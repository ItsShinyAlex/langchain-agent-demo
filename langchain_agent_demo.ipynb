{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\starm\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\core\\arrays\\masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from sqlalchemy import create_engine, text\n",
    "import pandas as pd\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.tools import tool\n",
    "from langchain.agents import create_tool_calling_agent, AgentExecutor\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser, CommaSeparatedListOutputParser, JsonOutputParser\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from langchain.tools import MoveFileTool, format_tool_to_openai_function\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.schema import HumanMessage, AIMessage, ChatMessage, FunctionMessage\n",
    "from langchain.tools import MoveFileTool, format_tool_to_openai_function\n",
    "from langchain.tools import BaseTool\n",
    "from typing import Optional, Type\n",
    "from langchain.agents import initialize_agent, Tool\n",
    "from langchain.agents import AgentType\n",
    "from langchain_openai import ChatOpenAI\n",
    "import json\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy\n",
    "\n",
    "\n",
    "# Load environment variables from the .env file\n",
    "load_dotenv()\n",
    "api_key = os.getenv('OPENAI_API_KEY')\n",
    "model = ChatOpenAI(model=\"gpt-3.5-turbo\", api_key=api_key)\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_colwidth', None) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: langchainNote: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Version: 0.2.5\n",
      "Summary: Building applications with LLMs through composability\n",
      "Home-page: https://github.com/langchain-ai/langchain\n",
      "Author: \n",
      "Author-email: \n",
      "License: MIT\n",
      "Location: C:\\Users\\starm\\AppData\\Roaming\\Python\\Python311\\site-packages\n",
      "Requires: aiohttp, langchain-core, langchain-text-splitters, langsmith, numpy, pydantic, PyYAML, requests, SQLAlchemy, tenacity\n",
      "Required-by: langchain-community\n"
     ]
    }
   ],
   "source": [
    "pip show langchain\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "TEST_MAIL = 'admin@platform.com'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'password'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getenv('CONSULTANT_PASSWORD')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "base_url = 'https://dashboard.colorines.paitesting.com/api'\n",
    "\n",
    "# Set the URL for the token API\n",
    "url_token = base_url+\"/v1/token\"\n",
    "\n",
    "# Set the data for the POST request\n",
    "data = {\n",
    "    \"email\": \"sale@platform.com\",\n",
    "    \"password\": os.getenv('CONSULTANT_PASSWORD'),\n",
    "    \"device_name\": \"colorina_2\",\n",
    "    \"role\": \"consultant\"\n",
    "}\n",
    "\n",
    "# Send a POST request\n",
    "response = requests.post(url_token, json=data)\n",
    "\n",
    "#print(response)\n",
    "\n",
    "# Extract the token from the response\n",
    "token = response.json().get('data').get('token')\n",
    "\n",
    "#print(\"Token:\", token)\n",
    "token_str = f\"mi auth token: {token}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#TODO: API need to add a filter by 'is_active'\n",
    "\n",
    "def GetProperties(token: str):\n",
    "    headers = {\"Authorization\": f\"Bearer {token}\"}\n",
    "    url = \"https://dashboard.colorines.paitesting.com/api/v1/properties\"\n",
    "    params = {'include': 'step,project,development', 'filter[status]': 'available'} \n",
    "    try:\n",
    "        response = requests.get(url, headers=headers, params=params)\n",
    "        response.raise_for_status()  # Raise an exception for HTTP errors\n",
    "        \n",
    "        # Check if the response contains any content\n",
    "        if response.content:\n",
    "            data = response.json()\n",
    "        else:\n",
    "            return pd.DataFrame({\"error\": [\"Empty response from the server\"]})\n",
    "        \n",
    "    except requests.exceptions.RequestException as e:\n",
    "        return pd.DataFrame({\"error\": [str(e)]})\n",
    "    except ValueError as ve:\n",
    "        return pd.DataFrame({\"error\": [\"Error parsing JSON response\"]})\n",
    "    \n",
    "    # Check if the 'data' key exists and contains a list of dictionaries\n",
    "    if 'data' in data:\n",
    "        if isinstance(data['data'], list):\n",
    "            return pd.DataFrame(data['data'])\n",
    "        else:\n",
    "            return pd.DataFrame({\"error\": [\"'data' key does not contain a list\"]})\n",
    "    else:\n",
    "        return pd.DataFrame({\"error\": [\"'data' key not found in the response\"]})\n",
    "    \n",
    "#PREPROCESS projects\n",
    "def PreprocessProjects(df):\n",
    "    df['development_name'] = df['development'].apply(lambda x: x.get('name'))\n",
    "    \n",
    "    def filter_active_steps(steps):\n",
    "        return [step['step_number'] for step in steps if step['is_active']]\n",
    "\n",
    "    # Applying the function to create the new column\n",
    "    df['active_steps'] = df['steps'].apply(filter_active_steps)\n",
    "\n",
    "    return df\n",
    "\n",
    "#PREPROCESS Properties\n",
    "def PreprocessProperties(df):\n",
    "    df['project_name'] = df['project'].apply(lambda x: x.get('name'))\n",
    "    df['development_name'] = df['development'].apply(lambda x: x.get('name'))\n",
    "    df['step_number'] = df['step'].apply(lambda x: x.get('step_number')) #numero de etapa\n",
    "\n",
    "    def extract_total_amount(prices, currency_code):\n",
    "        total_amount = None  # Initialize to None or any default value as needed\n",
    "        for entry in prices:\n",
    "            if entry['type'] == 'property' and entry['currency_code'] == currency_code:\n",
    "                total_amount = entry['total_amount']\n",
    "                break  # Exit loop once found\n",
    "        return total_amount\n",
    "\n",
    "    # Extracting total_amount_mxn and total_amount_usd\n",
    "    df['total_amount_mxn'] = df['prices'].apply(lambda x: extract_total_amount(x, 'MXN'))\n",
    "    df['total_amount_usd'] = df['prices'].apply(lambda x: extract_total_amount(x, 'USD'))\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "# Example usage\n",
    "\n",
    "#df_properties = GetProperties(token)\n",
    "\n",
    "def GetProjects(token: str):\n",
    "    headers = {\"Authorization\": f\"Bearer {token}\"}\n",
    "    url = \"https://dashboard.colorines.paitesting.com/api/v1/projects\"\n",
    "    params = {'include': 'steps,development', 'is_active': 'True'} \n",
    "    try:\n",
    "        response = requests.get(url, headers=headers, params=params)\n",
    "        response.raise_for_status()  # Raise an exception for HTTP errors\n",
    "        data = response.json()\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        return pd.DataFrame({\"error\": [str(e)]})\n",
    "    \n",
    "    # Check if the 'data' key exists and contains a list of dictionaries\n",
    "    if 'data' in data:\n",
    "        if isinstance(data['data'], list):\n",
    "            return pd.DataFrame(data['data'])\n",
    "        else:\n",
    "            return pd.DataFrame({\"error\": [\"'data' key does not contain a list\"]})\n",
    "    else:\n",
    "        return pd.DataFrame({\"error\": [\"'data' key not found in the response\"]})\n",
    "\n",
    "def GetDevelopments(token: str):\n",
    "    headers = {\"Authorization\": f\"Bearer {token}\"}\n",
    "    url = \"https://dashboard.colorines.paitesting.com/api/v1/developments\"\n",
    "    try:\n",
    "        response = requests.get(url, headers=headers)\n",
    "        response.raise_for_status()  # Raise an exception for HTTP errors\n",
    "        data = response.json()\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        return pd.DataFrame({\"error\": [str(e)]})\n",
    "    \n",
    "    # Check if the 'data' key exists and contains a list of dictionaries\n",
    "    if 'data' in data:\n",
    "        if isinstance(data['data'], list):\n",
    "            return pd.DataFrame(data['data'])\n",
    "        else:\n",
    "            return pd.DataFrame({\"error\": [\"'data' key does not contain a list\"]})\n",
    "    else:\n",
    "        return pd.DataFrame({\"error\": [\"'data' key not found in the response\"]})\n",
    "\n",
    "# Example usage\n",
    "\n",
    "#df_devs = GetDevelopments(token)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def GetSales(token: str, status: str = None, customer_id: int = None, str_date: str = None, end_date: str = None):\n",
    "    headers = {\n",
    "        \"Authorization\": f\"Bearer {token}\",\n",
    "        \"Accept\": \"application/json\"  # Ensures the server knows you expect JSON\n",
    "    }\n",
    "    url = \"https://dashboard.colorines.paitesting.com/api/v1/sales\"\n",
    "    params={}\n",
    "    if status:\n",
    "        params.update({\"filter[status]\": status})\n",
    "        \n",
    "    if customer_id:\n",
    "        params.update({\"customer_id\": customer_id})\n",
    "        \n",
    "    if str_date and end_date:\n",
    "        two_dates = str_date+','+end_date\n",
    "        params.update({\"filter[created_at_between]\": two_dates})\n",
    "        \n",
    "    try:\n",
    "        response = requests.get(url, headers=headers, params=params)\n",
    "        #print(\"Status Code:\", response.status_code)  # Log the status code\n",
    "        #print(\"Response Body:\", response.text)   \n",
    "        response.raise_for_status()  # Raise an exception for HTTP errors\n",
    "        \n",
    "        # Check if the response contains any content\n",
    "        if response.content:\n",
    "            data = response.json()\n",
    "        else:\n",
    "            return pd.DataFrame({\"error\": [\"Empty response from the server\"]})\n",
    "        \n",
    "    except requests.exceptions.RequestException as e:\n",
    "        return pd.DataFrame({\"error\": [str(e)]})\n",
    "    except ValueError as ve:\n",
    "        return pd.DataFrame({\"error\": [\"Error parsing JSON response\"]})\n",
    "    \n",
    "    # Check if the 'data' key exists and contains a list of dictionaries\n",
    "    if 'data' in data:\n",
    "        if isinstance(data['data'], list):\n",
    "            return pd.DataFrame(data['data'])\n",
    "        else:\n",
    "            return pd.DataFrame({\"error\": [\"'data' key does not contain a list\"]})\n",
    "    else:\n",
    "        return pd.DataFrame({\"error\": [\"'data' key not found in the response\"]})\n",
    "\n",
    "def PreprocessSales(df):\n",
    "    df['property_name'] = df['property'].apply(lambda x: x.get('alias'))\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Customers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def GetCustomers(token: str):\n",
    "    headers = {\n",
    "        \"Authorization\": f\"Bearer {token}\",\n",
    "        \"Accept\": \"application/json\"  # Ensures the server knows you expect JSON\n",
    "    }\n",
    "    url = \"https://dashboard.colorines.paitesting.com/api/v1/customers\"\n",
    "\n",
    "    try:\n",
    "        response = requests.get(url, headers=headers)\n",
    "        response.raise_for_status()  # Raise an exception for HTTP errors\n",
    "        \n",
    "        # Check if the response contains any content\n",
    "        if response.content:\n",
    "            data = response.json()\n",
    "        else:\n",
    "            return pd.DataFrame({\"error\": [\"Empty response from the server\"]})\n",
    "        \n",
    "    except requests.exceptions.RequestException as e:\n",
    "        return pd.DataFrame({\"error\": [str(e)]})\n",
    "    except ValueError as ve:\n",
    "        return pd.DataFrame({\"error\": [\"Error parsing JSON response\"]})\n",
    "    \n",
    "    # Check if the 'data' key exists and contains a list of dictionaries\n",
    "    if 'data' in data:\n",
    "        if isinstance(data['data'], list):\n",
    "            return pd.DataFrame(data['data'])\n",
    "        else:\n",
    "            return pd.DataFrame({\"error\": [\"'data' key does not contain a list\"]})\n",
    "    else:\n",
    "        return pd.DataFrame({\"error\": [\"'data' key not found in the response\"]})\n",
    "\n",
    "def GetCustomerID(df, email):\n",
    "    df_filtered = df[df['email'] == email]\n",
    "    if (len(df_filtered)>0):\n",
    "        return df_filtered.iloc[0].id\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def CleanProjects(df):\n",
    "    df_clean = df[['name', 'development_name', 'active_steps']]\n",
    "    df_clean = df_clean.rename(columns={'name': 'nombre_proyecto', 'development_name': 'nombre_desarrollo', 'active_steps': 'etapa'})\n",
    "    return df_clean.to_json(orient='records', force_ascii=False)\n",
    "\n",
    "def CleanProperties(df):\n",
    "    df_clean = df[['alias', 'status', 'project_name', 'development_name', 'step_number', 'total_amount_mxn', 'total_amount_usd']]\n",
    "    \n",
    "    df_clean = df_clean.rename(columns={'alias': 'nombre_propiedad',\n",
    "                                        'project_name': 'nombre_proyecto',\n",
    "                                        'development_name': 'nombre_desarrollo',\n",
    "                                        'step_number': 'etapa',\n",
    "                                        'total_amount_mxn': 'precio_MXN',\n",
    "                                        'total_amount_usd': 'precio_USD'\n",
    "                                       })\n",
    "    return df_clean.to_json(orient='records', force_ascii=False)\n",
    "\n",
    "def CleanSalesByCustomer(df):\n",
    "    df_clean = df[['property_name', 'currency', 'reserve_amount', 'property_amount', 'property_discount_amount', 'down_payment_amount', 'down_payment_percent', 'number_installments', 'installments_amount', 'status', 'amount_total', 'amount_paid', 'amount_remaining', 'next_payment_date', 'advance_percent', 'overdue_installments_count', 'overdue_installments_amount']]\n",
    "    return df_clean.to_json(orient='records', force_ascii=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@tool\n",
    "def get_active_properties(token: str) -> str:\n",
    "    \"\"\"\n",
    "    Uses the token to fetch the active properties from colorines API.\n",
    "    \n",
    "    Args:\n",
    "        token (str): The authorization token required to access the API.\n",
    "\n",
    "    Returns:\n",
    "        str: The JSON response from the API as a string.\n",
    "    \"\"\"\n",
    "    properties_df = GetProperties(token)\n",
    "    properties_df = properties_df[properties_df['is_active'] == True]\n",
    "    \n",
    "\n",
    "    response = requests.get(url, headers=headers, params=params)\n",
    "    # Check if the response was successful\n",
    "    if response.status_code == 200:\n",
    "        try:\n",
    "            return json.dumps(response.json())  # Convert JSON response to string\n",
    "        except ValueError:  # Catch JSON errors\n",
    "            return json.dumps({\"error\": \"Error parsing JSON\"})\n",
    "    else:\n",
    "        return json.dumps({\"error\": f\"Received status code {response.status_code}\"})\n",
    "\n",
    "\n",
    "\n",
    "@tool\n",
    "def get_last_sale(token: str) -> str:\n",
    "    \"\"\"\n",
    "    Uses the token to fetch the last sale from colorines API.\n",
    "    \n",
    "    Args:\n",
    "        token (str): The authorization token required to access the API.\n",
    "\n",
    "    Returns:\n",
    "        str: The JSON response from the API as a string.\n",
    "    \"\"\"\n",
    "    headers = {\"Authorization\": f\"Bearer {token}\"}\n",
    "    url = \"https://dashboard.colorines.paitesting.com/api/v1/sales\"\n",
    "    params = {\"per_page\": 1, \"sort\": \"-created_at\"}\n",
    "    \n",
    "    try:\n",
    "        response = requests.get(url, headers=headers, params=params)\n",
    "        # Check if the response was successful\n",
    "        if response.status_code == 200:\n",
    "            try:\n",
    "                return json.dumps(response.json())  # Convert JSON response to string\n",
    "            except ValueError:  # Catch JSON errors\n",
    "                return json.dumps({\"error\": \"Error parsing JSON\"})\n",
    "        else:\n",
    "            return json.dumps({\"error\": f\"Received status code {response.status_code}\"})\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        return json.dumps({\"error\": str(e)})\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Properties, developments and Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@tool\n",
    "def get_active_projects(token: str) -> str:   \n",
    "    \"\"\"\n",
    "    Uses the token to fetch the active (available) projects from colorines API.\n",
    "    \n",
    "    Args:\n",
    "        token (str): The authorization token required to access the API.\n",
    "\n",
    "    Returns:\n",
    "        str: The JSON response from the API as a string.\n",
    "    \"\"\"\n",
    "    df = GetProjects(token)\n",
    "    pre_df = PreprocessProjects(df)\n",
    "    return CleanProjects(pre_df)\n",
    "    \n",
    "@tool\n",
    "def get_active_properties(token: str)-> str:\n",
    "    \"\"\"\n",
    "    Uses the token to fetch the active (available) properties from colorines API.\n",
    "    \n",
    "    Args:\n",
    "        token (str): The authorization token required to access the API.\n",
    "\n",
    "    Returns:\n",
    "        str: The JSON response from the API as a string.\n",
    "    \"\"\"\n",
    "    \n",
    "    df = GetProperties(token)\n",
    "    pre_df = PreprocessProperties(df)\n",
    "    return CleanProperties(pre_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@tool\n",
    "def count_sales_by_status(token: str, status: str)-> int:\n",
    "    \"\"\"\n",
    "    Count the number of sales the user has with a specific status.\n",
    "    \n",
    "    \n",
    "    Args:\n",
    "        token (str): The authorization token required to access the API.\n",
    "        status (str): The status to filter the API request. Acceptable status by the API: reserved, documents, contract, active, canceled, overdue, finalized, deeded.\n",
    "\n",
    "    Returns:\n",
    "        int: The number of sales with the requested status.\n",
    "    \"\"\"\n",
    "    \n",
    "    df = GetSales(token=token, status=status)\n",
    "    count = len(df)\n",
    "    return count\n",
    "\n",
    "@tool\n",
    "def get_sales_by_customer(token: str, email: str) -> str:\n",
    "    \"\"\"\n",
    "    Retrieves and returns a list of sales associated with a customer identified by their email.\n",
    "\n",
    "    This function performs the following steps:\n",
    "    1. Uses the provided email to search for the customer ID.\n",
    "    2. Retrieves the sales attached to that customer ID.\n",
    "    3. Returns relevant sales information in JSON format.\n",
    "\n",
    "    Args:\n",
    "        token (str): The authorization token required to access the API.\n",
    "        email (str): The email address used to identify the customer.\n",
    "\n",
    "    Returns:\n",
    "        str: A JSON response containing information about sales made to the customer.\n",
    "             The JSON includes details about each sale that will be listed to the user by the agent.\n",
    "    \"\"\"\n",
    "    # Function implementation here\n",
    "    customers = GetCustomers(token)\n",
    "    customer_id = GetCustomerID(customers, email=email)\n",
    "    if customer_id:\n",
    "        df = GetSales(token=token, customer_id=customer_id)\n",
    "        df = PreprocessSales(df)\n",
    "        return CleanSalesByCustomer(df)\n",
    "    else:\n",
    "        return 'No se encontró ningún cliente con ese correo electrónico, pregunta al cliente si el correo es correcto'\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def call_json_output_parser():\n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", \"Extract information from the Colorines API using the {token}.\\nFormatting Instructions: {format_instructions}\"),\n",
    "        (\"human\", \"{input}\")\n",
    "    ])\n",
    "\n",
    "    class Data(BaseModel):\n",
    "        data: str = Field(description=\"JSON with the response containing all the relevant information for the user\")\n",
    "        \n",
    "    parser = JsonOutputParser(pydantic_object=Data)\n",
    "\n",
    "    chain = prompt | model | parser\n",
    "    \n",
    "    return chain.invoke({\n",
    "        \"phrase\": \"The ingredients for a Margherita pizza are tomatoes, onions, cheese, basil\",\n",
    "        \"format_instructions\": parser.get_format_instructions()\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sales remake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Count sales\n",
    "class CountSalesInput(BaseModel):\n",
    "    \"\"\"Input to grant access to Colorines API.\"\"\"\n",
    "\n",
    "    token: str = Field(..., description=\"token to authenticate the user to consume the API\")\n",
    "    status: str = Field(..., description=\"Status to filter the sales to retrieve from the API. Acceptable status by the API: reserved, documents, contract, active, canceled, overdue, finalized, deeded\")\n",
    "    \n",
    "class CountSalesTool(BaseTool):\n",
    "    name = \"count_sales_by_status\"\n",
    "    description = \"Count the number of sales the user has with a specific status. You must input the auth token\"\n",
    "\n",
    "    def _run(self, token: str, status: str):\n",
    "        df = GetSales(token=token, status=status)\n",
    "        count = len(df)\n",
    "        return json.dumps({\"count\": count})  # Directly return JSON string\n",
    "\n",
    "\n",
    "    def _arun(self, token: str, status: str):\n",
    "        raise NotImplementedError(\"This tool does not support async\")\n",
    "\n",
    "    args_schema: Optional[Type[BaseModel]] = CountSalesInput\n",
    "    \n",
    "#list sales by email\n",
    "# Input schema for fetching sales by customer\n",
    "class GetSalesByCustomerInput(BaseModel):\n",
    "    \"\"\"Input to fetch sales by customer.\"\"\"\n",
    "\n",
    "    token: str = Field(..., description=\"Authorization token to access the API.\")\n",
    "    email: str = Field(..., description=\"Email address of the customer.\")\n",
    "\n",
    "# Tool class to retrieve sales by customer\n",
    "class GetSalesByCustomerTool(BaseTool):\n",
    "    name = \"get_sales_by_customer\"\n",
    "    description = \"Retrieve sales associated with a customer identified by email.\"\n",
    "\n",
    "    def _run(self, token: str, email: str):\n",
    "        \"\"\"\n",
    "        Retrieves and returns sales associated with a customer identified by email.\n",
    "\n",
    "        Args:\n",
    "            token (str): Authorization token to access the API.\n",
    "            email (str): Email address of the customer.\n",
    "\n",
    "        Returns:\n",
    "            str: JSON response containing information about sales made to the customer.\n",
    "        \"\"\"\n",
    "        # Replace these with your actual functions to fetch data\n",
    "        customers = GetCustomers(token)\n",
    "        customer_id = GetCustomerID(customers, email=email)\n",
    "        \n",
    "        if customer_id:\n",
    "            df = GetSales(token=token, customer_id=customer_id)\n",
    "            df = PreprocessSales(df)\n",
    "            return json.dumps(CleanSalesByCustomer(df))\n",
    "        else:\n",
    "            return json.dumps({\n",
    "                \"message\": \"No se encontró ningún cliente con ese correo electrónico. \"\n",
    "                           \"Verifica el correo proporcionado e intenta nuevamente.\"\n",
    "            })\n",
    "\n",
    "    def _arun(self, token: str, email: str):\n",
    "        raise NotImplementedError(\"This tool does not support async.\")\n",
    "\n",
    "    args_schema: Optional[Type[BaseModel]] = GetSalesByCustomerInput\n",
    "    \n",
    "\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import Optional, Type\n",
    "\n",
    "class GetSalesBetweenDatesInput(BaseModel):\n",
    "    \"\"\"\n",
    "    Defines the input schema for fetching sales between specified dates.\n",
    "    \"\"\"\n",
    "    token: str = Field(..., description=\"Authorization token required to access the API.\")\n",
    "    str_date: str = Field(..., description=\"Start date to search sales created in between. Format must be: 'yyyy-mm-dd'\")\n",
    "    end_date: str = Field(..., description=\"End date to search sales created in between. Format must be: 'yyyy-mm-dd'\")\n",
    "\n",
    "class GetSalesBetweenDatesTool(BaseTool):\n",
    "    name = \"get_sales_between_dates\"  \n",
    "    description = \"Retrieve sales in a range of two dates. If only one date is provided, the same date is used for both start and end dates.\"\n",
    "\n",
    "    def _run(self, token: str, str_date: str, end_date: str):\n",
    "        \"\"\"\n",
    "        Executes a query to retrieve sales that were created between two specified dates.\n",
    "\n",
    "        Args:\n",
    "            token (str): Authorization token to access the API.\n",
    "            str_date (str): Start date to begin the search for sales.\n",
    "            end_date (str): End date to end the search for sales.\n",
    "\n",
    "        Returns:\n",
    "            str: JSON response containing information about sales in the specified date range.\n",
    "        \"\"\"\n",
    "        if str_date and end_date:\n",
    "            df = GetSales(token=token, str_date=str_date, end_date=end_date)\n",
    "            df = PreprocessSales(df)\n",
    "            return json.dumps(CleanSalesByCustomer(df))\n",
    "        else:\n",
    "            return json.dumps({\n",
    "                \"message\": \"Both start and end dates must be provided.\"\n",
    "            })\n",
    "\n",
    "    def _arun(self, token: str, str_date: str, end_date: str):\n",
    "        raise NotImplementedError(\"This tool does not support asynchronous execution.\")\n",
    "\n",
    "    args_schema: Optional[Type[BaseModel]] = GetSalesBetweenDatesInput\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class MathOperationInput(BaseModel):\n",
    "    \"\"\"\n",
    "    Defines the input schema for a math operation with two factors.\n",
    "    \"\"\"\n",
    "    factor1: float = Field(..., description=\"The first factor for the operation.\")\n",
    "    factor2: float = Field(..., description=\"The second factor for the operation.\")\n",
    "\n",
    "class SumTool(BaseTool):\n",
    "    name = \"sum_factors\"\n",
    "    description = \"Sum two factors.\"\n",
    "\n",
    "    def _run(self, factor1: float, factor2: float):\n",
    "        \"\"\"\n",
    "        Sums two factors.\n",
    "\n",
    "        Args:\n",
    "            factor1 (float): The first factor.\n",
    "            factor2 (float): The second factor.\n",
    "\n",
    "        Returns:\n",
    "            str: JSON response containing the sum of the factors.\n",
    "        \"\"\"\n",
    "        result = factor1 + factor2\n",
    "        return json.dumps({\n",
    "            \"sum\": result\n",
    "        })\n",
    "\n",
    "    def _arun(self, factor1: float, factor2: float):\n",
    "        raise NotImplementedError(\"This tool does not support asynchronous execution.\")\n",
    "\n",
    "    args_schema: Optional[Type[BaseModel]] = MathOperationInput\n",
    "\n",
    "class MultiplyTool(BaseTool):\n",
    "    name = \"multiply_factors\"\n",
    "    description = \"Multiply two factors.\"\n",
    "\n",
    "    def _run(self, factor1: float, factor2: float):\n",
    "        \"\"\"\n",
    "        Multiplies two factors.\n",
    "\n",
    "        Args:\n",
    "            factor1 (float): The first factor.\n",
    "            factor2 (float): The second factor.\n",
    "\n",
    "        Returns:\n",
    "            str: JSON response containing the product of the factors.\n",
    "        \"\"\"\n",
    "        result = factor1 * factor2\n",
    "        return json.dumps({\n",
    "            \"product\": result\n",
    "        })\n",
    "\n",
    "    def _arun(self, factor1: float, factor2: float):\n",
    "        raise NotImplementedError(\"This tool does not support asynchronous execution.\")\n",
    "\n",
    "    args_schema: Optional[Type[BaseModel]] = MathOperationInput\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Half agent use, just to select Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#ChatGpt model to select tools\n",
    "model = ChatOpenAI(model=\"gpt-3.5-turbo\", api_key=api_key)\n",
    "\n",
    "#The tools classes\n",
    "tool_names = [CountSalesTool().name, GetSalesByCustomerTool().name, GetSalesBetweenDatesTool().name]\n",
    "tools = [CountSalesTool(), GetSalesByCustomerTool(), GetSalesBetweenDatesTool()]\n",
    "\n",
    "#tool_names = [MultiplyTool().name, SumTool().name]\n",
    "#tools = [MultiplySalesTool(), SumSalesTool()]\n",
    "\n",
    "#Format Tools for being usable by the model\n",
    "functions = [format_tool_to_openai_function(t) for t in tools]\n",
    "\n",
    "#Token append to input string\n",
    "token_str = f\"mi auth token: {token}\"\n",
    "\n",
    "#Uses the model to predict which tool use, but we return the tool response directly\n",
    "def smart_tool_selector(input_str, token_str, model, functions, tool_names):\n",
    "    \"\"\"\n",
    "    Uses a machine learning model to predict which tool to use based on input,\n",
    "    then directly returns the response from the selected tool.\n",
    "\n",
    "    Args:\n",
    "    - input_str (str): The input string to be processed.\n",
    "    - token_str (str): The token string to be included in the input.\n",
    "    - model: The machine learning model used to predict the tool.\n",
    "    - functions (list): List of functions or tools available for selection.\n",
    "\n",
    "    Returns:\n",
    "    - tool_result: The result returned by the selected tool.\n",
    "    - _args (dict): Arguments parsed from the AI model's function call prediction.\n",
    "    - ai_message: Message object containing details of the AI model's prediction.\n",
    "    \"\"\"\n",
    "    # Prepare input data for the model prediction\n",
    "    input_data = {\n",
    "        \"input\": f\"{input_str} {token_str}\"\n",
    "    }\n",
    "    \n",
    "    # Predict the tool to use based on input using the machine learning model\n",
    "    ai_message = model.predict_messages([HumanMessage(content=input_data['input'])], functions=functions)\n",
    "    \n",
    "    # Extract arguments for the tool from the AI model's function call prediction\n",
    "    _args = json.loads(ai_message.additional_kwargs['function_call'].get('arguments'))\n",
    "    \n",
    "    print(_args)\n",
    "    \n",
    "    tool_name = ai_message.additional_kwargs['function_call']['name']\n",
    "    tool_index = tool_names.index(tool_name)\n",
    "    # Execute the selected tool and capture its result\n",
    "    tool_result = tools[tool_index](_args)  # Pass _args as keyword arguments\n",
    "    \n",
    "    # Return the tool's result, parsed arguments, and AI message\n",
    "    return tool_result, _args, ai_message\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'token': '2160|aO5WEkKvSlV2omFuvv3Jay74ZYy7ULTdirtM8j33d89df04f', 'str_date': '2024-01-07', 'end_date': '2024-01-07'}\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'property'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[52], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m input_str \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmuestrame las ventas entre el 7 de enero del 2024 ?\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m----> 2\u001b[0m result, args, msg \u001b[38;5;241m=\u001b[39m \u001b[43msmart_tool_selector\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_str\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtoken_str\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_names\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(msg)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(args)\n",
      "Cell \u001b[1;32mIn[48], line 50\u001b[0m, in \u001b[0;36msmart_tool_selector\u001b[1;34m(input_str, token_str, model, functions, tool_names)\u001b[0m\n\u001b[0;32m     48\u001b[0m tool_index \u001b[38;5;241m=\u001b[39m tool_names\u001b[38;5;241m.\u001b[39mindex(tool_name)\n\u001b[0;32m     49\u001b[0m \u001b[38;5;66;03m# Execute the selected tool and capture its result\u001b[39;00m\n\u001b[1;32m---> 50\u001b[0m tool_result \u001b[38;5;241m=\u001b[39m \u001b[43mtools\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtool_index\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_args\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Pass _args as keyword arguments\u001b[39;00m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;66;03m# Return the tool's result, parsed arguments, and AI message\u001b[39;00m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m tool_result, _args, ai_message\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\langchain_core\\_api\\deprecation.py:168\u001b[0m, in \u001b[0;36mdeprecated.<locals>.deprecate.<locals>.warning_emitting_wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    166\u001b[0m     warned \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    167\u001b[0m     emit_warning()\n\u001b[1;32m--> 168\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\langchain_core\\tools.py:567\u001b[0m, in \u001b[0;36mBaseTool.__call__\u001b[1;34m(self, tool_input, callbacks)\u001b[0m\n\u001b[0;32m    564\u001b[0m \u001b[38;5;129m@deprecated\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m0.1.47\u001b[39m\u001b[38;5;124m\"\u001b[39m, alternative\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minvoke\u001b[39m\u001b[38;5;124m\"\u001b[39m, removal\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m0.3.0\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    565\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, tool_input: \u001b[38;5;28mstr\u001b[39m, callbacks: Callbacks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n\u001b[0;32m    566\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Make tool callable.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 567\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtool_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\langchain_core\\tools.py:452\u001b[0m, in \u001b[0;36mBaseTool.run\u001b[1;34m(self, tool_input, verbose, start_color, color, callbacks, tags, metadata, run_name, run_id, config, **kwargs)\u001b[0m\n\u001b[0;32m    450\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mException\u001b[39;00m, \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    451\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_tool_error(e)\n\u001b[1;32m--> 452\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[0;32m    453\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    454\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_tool_end(observation, color\u001b[38;5;241m=\u001b[39mcolor, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\langchain_core\\tools.py:413\u001b[0m, in \u001b[0;36mBaseTool.run\u001b[1;34m(self, tool_input, verbose, start_color, color, callbacks, tags, metadata, run_name, run_id, config, **kwargs)\u001b[0m\n\u001b[0;32m    406\u001b[0m     parsed_input \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_parse_input(tool_input)\n\u001b[0;32m    407\u001b[0m     tool_args, tool_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_to_args_and_kwargs(parsed_input)\n\u001b[0;32m    408\u001b[0m     observation \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    409\u001b[0m         context\u001b[38;5;241m.\u001b[39mrun(\n\u001b[0;32m    410\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run, \u001b[38;5;241m*\u001b[39mtool_args, run_manager\u001b[38;5;241m=\u001b[39mrun_manager, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mtool_kwargs\n\u001b[0;32m    411\u001b[0m         )\n\u001b[0;32m    412\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[1;32m--> 413\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mtool_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mtool_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    414\u001b[0m     )\n\u001b[0;32m    415\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ValidationError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    416\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle_validation_error:\n",
      "Cell \u001b[1;32mIn[12], line 96\u001b[0m, in \u001b[0;36mGetSalesBetweenDatesTool._run\u001b[1;34m(self, token, str_date, end_date)\u001b[0m\n\u001b[0;32m     94\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m str_date \u001b[38;5;129;01mand\u001b[39;00m end_date:\n\u001b[0;32m     95\u001b[0m     df \u001b[38;5;241m=\u001b[39m GetSales(token\u001b[38;5;241m=\u001b[39mtoken, str_date\u001b[38;5;241m=\u001b[39mstr_date, end_date\u001b[38;5;241m=\u001b[39mend_date)\n\u001b[1;32m---> 96\u001b[0m     df \u001b[38;5;241m=\u001b[39m \u001b[43mPreprocessSales\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     97\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m json\u001b[38;5;241m.\u001b[39mdumps(CleanSalesByCustomer(df))\n\u001b[0;32m     98\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "Cell \u001b[1;32mIn[5], line 45\u001b[0m, in \u001b[0;36mPreprocessSales\u001b[1;34m(df)\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mPreprocessSales\u001b[39m(df):\n\u001b[1;32m---> 45\u001b[0m     df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mproperty_name\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mproperty\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: x\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124malias\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[0;32m     47\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m df\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\core\\frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\core\\indexes\\range.py:417\u001b[0m, in \u001b[0;36mRangeIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    415\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m    416\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Hashable):\n\u001b[1;32m--> 417\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key)\n\u001b[0;32m    418\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n\u001b[0;32m    419\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'property'"
     ]
    }
   ],
   "source": [
    "input_str = 'muestrame las ventas entre el 7 de enero del 2024 y primero de junio del 2024?'\n",
    "result, args, msg = smart_tool_selector(input_str, token_str, model, functions, tool_names)\n",
    "print(msg)\n",
    "print(args)\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['multiply_factors', 'sum_factors']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'function_call'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[47], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m input_str \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuanto es 2 + 3?\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m----> 2\u001b[0m result, args, msg \u001b[38;5;241m=\u001b[39m \u001b[43msmart_tool_selector\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_str\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_names\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(msg)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(args)\n",
      "Cell \u001b[1;32mIn[46], line 42\u001b[0m, in \u001b[0;36msmart_tool_selector\u001b[1;34m(input_str, model, functions, tool_names)\u001b[0m\n\u001b[0;32m     39\u001b[0m ai_message \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict_messages([HumanMessage(content\u001b[38;5;241m=\u001b[39minput_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput\u001b[39m\u001b[38;5;124m'\u001b[39m])], functions\u001b[38;5;241m=\u001b[39mfunctions)\n\u001b[0;32m     41\u001b[0m \u001b[38;5;66;03m# Extract arguments for the tool from the AI model's function call prediction\u001b[39;00m\n\u001b[1;32m---> 42\u001b[0m _args \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mloads(\u001b[43mai_message\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madditional_kwargs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfunction_call\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124marguments\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[0;32m     44\u001b[0m \u001b[38;5;28mprint\u001b[39m(_args)\n\u001b[0;32m     46\u001b[0m tool_name \u001b[38;5;241m=\u001b[39m ai_message\u001b[38;5;241m.\u001b[39madditional_kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfunction_call\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[1;31mKeyError\u001b[0m: 'function_call'"
     ]
    }
   ],
   "source": [
    "input_str = 'cuanto es 2 + 3?'\n",
    "result, args, msg = smart_tool_selector(input_str, model, functions, tool_names)\n",
    "print(msg)\n",
    "print(args)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "input_str='muéstrame las ventas del cliente admin@platform.com'\n",
    "result, args, msg = smart_tool_selector(input_str, token_str, model, functions, tool_names)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'admin@platform.com'"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TEST_MAIL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stable old agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "    \n",
    "# Define the prompt template\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"you're a helpful assistant who will use the {token} to use the tools to bring information to the user\"),\n",
    "    (\"human\", \"{input}\"),\n",
    "    (\"placeholder\", \"{agent_scratchpad}\"),\n",
    "])\n",
    "\n",
    "# Example of integrating with langchain agent framework\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo\", api_key=api_key)\n",
    "\n",
    "# Add the `get_sales` function to the list of tools\n",
    "tools_api = [get_last_sale, get_active_projects, count_sales_by_status, get_sales_by_customer] \n",
    "\n",
    "# Create the agent\n",
    "agent = create_tool_calling_agent(llm, tools_api, prompt)\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools_api, verbose=True)\n",
    "\n",
    "# Example usage:\n",
    "# token = 'your_actual_token_here'\n",
    "# base_url = 'https://api.yourdomain.com'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'admin@platform.com'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TEST_MAIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `count_sales_by_status` with `{'token': '2134|lFXht7lxyqFZ4N25J08O0ffzUHxf5gtJLIzzzJ4a6a41aaf3', 'status': 'documents'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[38;5;200m\u001b[1;3m11\u001b[0m\u001b[32;1m\u001b[1;3mTienes un total de 11 ventas en la etapa de documentos.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'cuantas ventas en la etapa de documentos tengo?',\n",
       " 'token': '2134|lFXht7lxyqFZ4N25J08O0ffzUHxf5gtJLIzzzJ4a6a41aaf3',\n",
       " 'output': 'Tienes un total de 11 ventas en la etapa de documentos.'}"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_data = {\n",
    "    \"input\": \"cuantas ventas en la etapa de documentos tengo?\",\n",
    "    \"token\": token\n",
    "}\n",
    "\n",
    "# Invoke the agent\n",
    "agent_executor.invoke(input_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demo from zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import SimpleChain\n",
    "\n",
    "# Configuración del modelo\n",
    "model = ChatOpenAI(api_key='your_openai_api_key')\n",
    "\n",
    "# Definición de herramientas\n",
    "def query_api(endpoint, params):\n",
    "    response = requests.get(endpoint, params=params)\n",
    "    return response.json()\n",
    "\n",
    "tools = {\n",
    "    'query_api': GetSalesByCustomerTool\n",
    "}\n",
    "\n",
    "# Creación del prompt\n",
    "prompt = \"\"\"\n",
    "Actúa como un asistente inteligente que consulta la API de nuestro cliente. Cuando recibas una solicitud, utiliza las herramientas disponibles para obtener la información necesaria y devuélvela en formato JSON.\n",
    "\n",
    "Solicitud: {user_input}\n",
    "\"\"\"\n",
    "\n",
    "# Configuración del parser\n",
    "def parse_response(response):\n",
    "    return {\n",
    "        'status': response.get('status'),\n",
    "        'data': response.get('data')\n",
    "    }\n",
    "\n",
    "# Integración de LangChain\n",
    "chain = SimpleChain(\n",
    "    model=model,\n",
    "    prompt=prompt,\n",
    "    tools=tools,\n",
    "    parser=parse_response\n",
    ")\n",
    "\n",
    "# Uso del chatbot\n",
    "user_input = \"Consultar datos del cliente con ID 123\"\n",
    "response = chain.run(user_input)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demo json out parser langchain doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "class Add(BaseModel):\n",
    "    \"\"\"Add two integers together.\"\"\"\n",
    "\n",
    "    a: int = Field(..., description=\"First integer\")\n",
    "    b: int = Field(..., description=\"Second integer\")\n",
    "\n",
    "\n",
    "class Multiply(BaseModel):\n",
    "    \"\"\"Multiply two integers together.\"\"\"\n",
    "\n",
    "    a: int = Field(..., description=\"First integer\")\n",
    "    b: int = Field(..., description=\"Second integer\")\n",
    "\n",
    "\n",
    "tools = [Add, Multiply]\n",
    "\n",
    "llm_with_tools = model.bind_tools(tools)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Define your desired data structure.\n",
    "class Result(BaseModel):\n",
    "    data: str = Field(description=\"Data with the API response\")\n",
    "\n",
    "\n",
    "# And a query intented to prompt a language model to populate the data structure.\n",
    "\n",
    "input_str = \"Can you tell me my auth token?\"\n",
    "\n",
    "input_data = {\n",
    "    \"input\": f\"{input_str} {token_str}\"\n",
    "}\n",
    "\n",
    "# Set up a parser + inject instructions into the prompt template.\n",
    "parser = JsonOutputParser(pydantic_object=Result)\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=\"Answer the user query.\\n{format_instructions}\\n{query}\\n\",\n",
    "    input_variables=[\"query\"],\n",
    "    partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
    ")\n",
    "\n",
    "chain = prompt | model | parser\n",
    "\n",
    "#chain.invoke({\"query\": input_data})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_I3zUsKh7jKOKHSRGZ1VZiUb0', 'function': {'arguments': '{\"a\":3,\"b\":12}', 'name': 'Multiply'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 18, 'prompt_tokens': 95, 'total_tokens': 113}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-d7822315-c674-483a-bee9-567e1cd386b4-0', tool_calls=[{'name': 'Multiply', 'args': {'a': 3, 'b': 12}, 'id': 'call_I3zUsKh7jKOKHSRGZ1VZiUb0'}], usage_metadata={'input_tokens': 95, 'output_tokens': 18, 'total_tokens': 113})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Chatgpt tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'ToolSelector' from 'langchain.tools' (C:\\Users\\starm\\AppData\\Roaming\\Python\\Python311\\site-packages\\langchain\\tools\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtools\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Tool, ToolSelector\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'ToolSelector' from 'langchain.tools' (C:\\Users\\starm\\AppData\\Roaming\\Python\\Python311\\site-packages\\langchain\\tools\\__init__.py)"
     ]
    }
   ],
   "source": [
    "from langchain.tools import Tool, ToolSelector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'Model' from 'langchain' (C:\\Users\\starm\\AppData\\Roaming\\Python\\Python311\\site-packages\\langchain\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mopenai\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LLMChain, Prompt, Model, JsonOutputParser\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtools\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Tool\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Set your OpenAI API key\u001b[39;00m\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'Model' from 'langchain' (C:\\Users\\starm\\AppData\\Roaming\\Python\\Python311\\site-packages\\langchain\\__init__.py)"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import openai\n",
    "from langchain import LLMChain, Prompt, Model, JsonOutputParser\n",
    "from langchain.tools import Tool\n",
    "\n",
    "# Set your OpenAI API key\n",
    "openai.api_key = 'your-openai-api-key'\n",
    "\n",
    "# Define the prompt template\n",
    "prompt_template = \"\"\"\n",
    "You are a helpful assistant. Answer the following question in a JSON format. If the question involves arithmetic calculations, use the provided tools to compute the answer.\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "\n",
    "# Create the Prompt object\n",
    "prompt = Prompt(template=prompt_template)\n",
    "\n",
    "# Define the model (ChatGPT)\n",
    "model = Model(\n",
    "    model_name=\"gpt-3.5-turbo\",  # You can change this to the desired model\n",
    "    max_tokens=150  # Adjust based on your needs\n",
    ")\n",
    "\n",
    "# Define the summation tool\n",
    "def sum_tool(question):\n",
    "    try:\n",
    "        # Extract numbers from the question and calculate the sum\n",
    "        numbers = [float(num) for num in question.split() if num.replace('.', '', 1).isdigit()]\n",
    "        result = sum(numbers)\n",
    "        return {\"result\": result}\n",
    "    except Exception as e:\n",
    "        return {\"error\": str(e)}\n",
    "\n",
    "# Create a Tool object for the summation tool\n",
    "sum_tool_obj = Tool(\n",
    "    name=\"SumTool\",\n",
    "    description=\"Performs summation of numbers.\",\n",
    "    func=sum_tool\n",
    ")\n",
    "\n",
    "# Define the multiplication tool\n",
    "def multiply_tool(question):\n",
    "    try:\n",
    "        # Extract numbers from the question and calculate the product\n",
    "        numbers = [float(num) for num in question.split() if num.replace('.', '', 1).isdigit()]\n",
    "        result = 1\n",
    "        for num in numbers:\n",
    "            result *= num\n",
    "        return {\"result\": result}\n",
    "    except Exception as e:\n",
    "        return {\"error\": str(e)}\n",
    "\n",
    "# Create a Tool object for the multiplication tool\n",
    "multiply_tool_obj = Tool(\n",
    "    name=\"MultiplyTool\",\n",
    "    description=\"Performs multiplication of numbers.\",\n",
    "    func=multiply_tool\n",
    ")\n",
    "\n",
    "# Define the JSON output parser\n",
    "json_output_parser = JsonOutputParser()\n",
    "\n",
    "# Create the chain with tools\n",
    "chain = LLMChain(\n",
    "    prompt=prompt,\n",
    "    model=model,\n",
    "    tools=[sum_tool_obj, multiply_tool_obj],\n",
    "    output_parser=json_output_parser\n",
    ")\n",
    "\n",
    "# Define a function to run the chain\n",
    "def run_chain(question):\n",
    "    input_data = {\"question\": question}\n",
    "    result = chain.run(input_data)\n",
    "    return result\n",
    "\n",
    "# Example usage\n",
    "question = \"What is the sum of 5 and 3?\"\n",
    "response = run_chain(question)\n",
    "print(response)\n",
    "\n",
    "# Another example\n",
    "question = \"What is the product of 5 and 3?\"\n",
    "response = run_chain(question)\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
