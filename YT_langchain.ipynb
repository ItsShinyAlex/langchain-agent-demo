{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pNH6I4yNTvxk"
   },
   "source": [
    "## 1. Installing libraries and connect to LLMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "W2OZYI5XlXXC",
    "outputId": "23a64120-5037-4ebe-efba-f8f8b5b45f14"
   },
   "outputs": [],
   "source": [
    "!pip install -qU  \\\n",
    "  python-dotenv \\\n",
    "  langchain \\\n",
    "  langchain-community \\\n",
    "  openai \\\n",
    "  anthropic \\\n",
    "  langchain-openai \\\n",
    "  langchain-anthropic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aZbN7ti31Adv",
    "outputId": "f37de950-dc4f-4dff-83c4-784e7eda65b7"
   },
   "outputs": [],
   "source": [
    "# Load the API keys from the .env file\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "api_key = os.getenv('OPENAI_API_KEY')\n",
    "model = ChatOpenAI(model=\"gpt-3.5-turbo\", api_key=api_key, temperature=0)\n",
    "llm_gpt4 = model #not techinaly correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "j8K_zG4D1HqA"
   },
   "outputs": [],
   "source": [
    "# Connect to OpenAI and Anthropic\n",
    "\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "llm_claude3 = ChatAnthropic(model='claude-3-opus-20240229')\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "llm_gpt4 = ChatOpenAI(model=\"gpt-4o\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "sjfYGNmd1OfD"
   },
   "outputs": [],
   "source": [
    "# Basic request using system and human/user message\n",
    "\n",
    "system_prompt=\"\"\"\n",
    "You explain things to people like they are five year olds.\n",
    "\"\"\"\n",
    "user_prompt=f\"\"\"\n",
    "What is LangChain?\n",
    "\"\"\"\n",
    "\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "import textwrap\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(content=system_prompt),\n",
    "    HumanMessage(content=user_prompt),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "fIOYvhTR1u2X"
   },
   "outputs": [],
   "source": [
    "response=llm_gpt4.invoke(messages)\n",
    "answer = textwrap.fill(response.content, width=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tulS9RsH1r86",
    "outputId": "5f24c113-f6a5-4c0d-a5a5-7932cb60f74d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Okay! Imagine you have a big box of colorful building blocks, and you want to build something\n",
      "awesome like a tall tower or a cool castle. Each block is like a piece of a puzzle that you put\n",
      "together.  LangChain is like a special set of instructions or tools that helps people put together\n",
      "different pieces of computer programs, especially ones that use language, like talking to a robot or\n",
      "finding information in books. Just like your building blocks, LangChain helps connect these pieces\n",
      "so they work nicely together and build something really cool!  So, it's like having a helper that\n",
      "shows you how to connect your blocks to make your tower super tall and strong!\n"
     ]
    }
   ],
   "source": [
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jFugvpEcTpdR"
   },
   "source": [
    "## 2. Chains, Prompts and Loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "mhgtPPEcN_dJ"
   },
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "7NZqTnzIOL0_"
   },
   "outputs": [],
   "source": [
    "# Create a simple prompt template\n",
    "\n",
    "prompt_template = \"\"\"\n",
    "You are a helpful assistant that explains AI topics. Given the following input:\n",
    "{topic}\n",
    "Provide an explanation of the given topic.\n",
    "\"\"\"\n",
    "\n",
    "# Create the prompt from the prompt template\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"topic\"],\n",
    "    template=prompt_template,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "PDwGnPSeP_q3"
   },
   "outputs": [],
   "source": [
    "# Assemble the chain using the pipe operator \"|\", more on that later\n",
    "chain = prompt | llm_gpt4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 411
    },
    "id": "Wcb1W45pQEFJ",
    "outputId": "50400825-244f-4d39-a819-3f65b3def2e6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'LangChain is a decentralized artificial intelligence platform that aims to connect AI developers and users through a blockchain-based network. It allows developers to create and deploy AI models, while users can access these models for various applications such as natural language processing, image recognition, and more. LangChain utilizes blockchain technology to ensure transparency, security, and fair compensation for both developers and users within the AI ecosystem.'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"topic\":\"What is LangChain\"}).content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "a6L3kvBFRasB"
   },
   "outputs": [],
   "source": [
    "! pip install --upgrade --quiet  youtube-transcript-api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "FTkY3wQAOztq"
   },
   "outputs": [],
   "source": [
    "# Import the Youtube Loader from the LangChain community\n",
    "\n",
    "from langchain_community.document_loaders import YoutubeLoader\n",
    "\n",
    "loader = YoutubeLoader.from_youtube_url(\n",
    "    \"https://www.youtube.com/watch?v=AOEGOhkGtjI\", add_video_info=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "UuclzSCERocY"
   },
   "outputs": [],
   "source": [
    "# Load the video transcript as documents\n",
    "docs=loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WwFI1F1hneGi",
    "outputId": "2fad1574-6119-40e6-df43-788440d86f48"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'AOEGOhkGtjI'}, page_content=\"so now we have Lama 3 from meta and this model is definitely going to be a GameChanger when it comes to analyzing data with llms here I have L 3 on gr cloud and not only are the text to SQL chains blazing fast they're also capable of generating quite Advanced SQL and almost on par with the high IQ llms if we Implement one additional tweak so in this video I'm going to show you how we can tweak the SQL chains to maximize the performance of Lama 3 we're going to have a look at some of the insights that Lama three is capable of extracting and finally I'm going to briefly discuss some of the implications for llm based data analysis on l.a. comom you can read about Lama 3 and some of the capabilities of the model you can see how the model compares to other popular llms specifically the 70b model that I'm going to be using in this video is compared to Gemini and CLA 3 Sunnet and there's also a link that lets you request access to Lama 3 but this is not what I'll be doing I'm going to be using Gro Cloud because it's the fastest and easiest way to get started using llama 3 and as you can see the 70b model is already available on gr Cloud so I'll just grab the API key and then I'm ready to build the SQL chains with L chain all right the first thing I'm going to do is I'm going to set up the cop notebook and pip install the required libraries then I'll connect to Bay and fetch the schema information from tables in a data set I'll be installing python. EnV to fetch the API Keys Lang chain Gro the Lang chain Gro connector and Google Cloud B quy then I have uploaded myv file with the API keys I have my Google cloud service account key DBQ key. jjon then I have two functions that extracts the schema information from bit query in a schema. py file and this is the same functions that I've been using in the earlier videos that lets me extract and feed the scheme information from bitre to the chain all right so I'm just going to load the environment variables and then I'm going to connect to biy and the data set I'm using is the same data set I used in the last video in the dashboard video it is an e-commerce data set with four tables customers orders products and customer taxs and the two functions in the schema. py file allows me to extract the schema information from the data set as you can see here so now let's connect to Lama 3 on Gro cloud and set set up the SQL chain using Lang chain expression language to connect to Lama 3 on groc cloud we import chat Gro from Lang chain grock and then we instantiate it with a model name in this case I'm using Lama 370b and the prom template will be injecting three things first I'll inject the schema information I'm extracting from the bit crate data set then I'm injecting the main question or the query and finally I'll be injecting a a message history and the message history is The Tweak I mentioned in the beginning so I'm going to have Lama 3 generate SQL code and then I'll use the bitr client to execute that SQL code and if there's an error I'm going to catch the error and feed it back to the chain and this allows me to make the chains self-correcting which is useful when we're dealing with a model that is of a low IQ the SQL chain is assembled in the usual way I'll use a runnable path through to to inject the schema information and to inject the messages of the message history that contains the errors then I use my prompt the language model and a string output passer and this is what we need to generate the SQL code from a prompt now let's move on to generate some insights with this setup I had difficulties having Lama 3 return clean executable SQL so I had to write a function that lets me extract the SQL code from the response and in this extract SQL function I'm simply using regex to extract the SQL from whatever the language model is returning to wrap it all up I'm creating a function that takes a prompt and a number of attempts as input and then it will generate the SQL using the Lang chain SQL chain and try to execute that SQL up to five times and whenever there's an error I'm going to collect the error and feed it back to the chain and try again and in this way the chain will be self-corrected ing because the llm will understand the error message okay so let's try this the first prompt I'm going to give L three is the following give me a list of the best customers including their rank their first name last name and email and the products they purchased and this one it got in the first attempt so the query executed successfully and we can then have a look at the data frame and this is essentially an audience that you could use for marketing purposes you normally create an audience like this in a customer data platform now let's try a different one I'll do a classical one show me the revenue generated in the last 30 days broken down by acquisition Channel and here you can see that the first attempt is unsuccessful it fails but feeding back the error message makes the second attempt successful and here we have Revenue broken down by acquisition source let's do another audience let's say I want the top 100 customers with the highest purchase frequency but with an under average aov and again we see that the first attempt fails and the second attempt is successful and here we only got the names let's say that we want to include the frequency and the aov as well to get the full overview and here we see that the first attempt fails the second attempt also fails but the third attempt is a success and here we have the full audience data frame with the purchase frequency and the average order value so this is very useful so we can use llama 3 for generating insights if we just implement this small tweak of catching the errors and feeding it back to the chain all right so what are the implications of this first of all we now know that with Lama 3 open source llms can be used to generate insights and this is very good news for privacy sensitive use cases so use cases where you want to feed sensitive customer data back to the llm and in real sensitive use cases you probably don't want to use gr Cloud you want to use Lama 3 locally this is also very good news for query heavy applications so text tosql applications can be query heavy if they're rolled out in a big organization so there's a cost consideration that might be worth looking into now Gro cloud is all about realtime gen inference so Lama 3 on gr cloud is going to be really useful for Consumer facing applications where speed is necessary finally I think it's pretty clear now that data pipelines dashboards reports and so on will be llm generated in the future and not so distant future so if you are a data analyst or data engineer you should really pay attention to this and learn this new technology all right that's it for now if you enjoyed this video I suggest you check out one of the other videos on generating SQL with llm chains thanks for watching\")]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "4RWjlF2RRrFE"
   },
   "outputs": [],
   "source": [
    "transcript=docs[0].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "kjtcIV1mR1FK"
   },
   "outputs": [],
   "source": [
    "# We can now use the transcript in a chain\n",
    "prompt_template = \"\"\"\n",
    "You are a helpful assistant that explains YT videos. Given the following video transcript:\n",
    "{video_transcript}\n",
    "Give a summary.\n",
    "\"\"\"\n",
    "\n",
    "# Create the prompt\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"video_transcript\"],\n",
    "    template=prompt_template,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "jXALdqNiSP3S"
   },
   "outputs": [],
   "source": [
    "chain = prompt | llm_gpt4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 196
    },
    "id": "_6RbQR5ESUDR",
    "outputId": "55a664d8-a096-4717-f40f-3dc8e7b28f37"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The video discusses the capabilities of the Lama 3 model from Meta for analyzing data with LLMS. The presenter demonstrates how to maximize the performance of Lama 3 by tweaking SQL chains and extracting insights from data sets using the model. They also highlight the implications of using Lama 3 for generating insights in privacy-sensitive use cases and query-heavy applications. The video emphasizes the potential of LLMS like Lama 3 in automating data analysis tasks and suggests that data analysts and engineers should pay attention to this technology.'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Note that we can just feed the chain the docs without extracting the content as text\n",
    "\n",
    "chain.invoke({\"video_transcript\":docs}).content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "14-68lwFSsxI"
   },
   "outputs": [],
   "source": [
    "from langchain.chains.combine_documents import create_stuff_documents_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "OYI-Ej1DSw9j"
   },
   "outputs": [],
   "source": [
    "# The create_stuff_documents_chain takes a list of docs and formats them all into a prompt\n",
    "\n",
    "prompt_template = \"\"\"\n",
    "You are a helpful assistant that explains AI topics. Given the following context:\n",
    "{context}\n",
    "Summarize what Llama 3 can do.\n",
    "\"\"\"\n",
    "\n",
    "# Create the prompt\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"context\"],\n",
    "    template=prompt_template,\n",
    ")\n",
    "\n",
    "chain = create_stuff_documents_chain(llm_gpt4, prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "vKAUFQElTPHh"
   },
   "outputs": [],
   "source": [
    "#docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 196
    },
    "id": "Lb_RBPa2TSNf",
    "outputId": "c13389ad-809a-4e89-a790-743ab3114000"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Llama 3 from Meta is a model that can analyze data with LLMS, specifically excelling in text to SQL chains. It is capable of generating advanced SQL queries quickly and efficiently, almost on par with high IQ LLMS. By implementing a small tweak to catch and correct errors, Llama 3 can generate insights and execute SQL queries successfully. This makes it a valuable tool for generating audience lists, revenue breakdowns, and other data insights. Llama 3 has implications for privacy-sensitive use cases, query-heavy applications, real-time inference, and the future of data pipelines, dashboards, and reports. It is a powerful tool for data analysts and engineers to learn and incorporate into their work.'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"context\": docs})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HDpbfZb1TknL"
   },
   "source": [
    "## 3. LCEL & Runnables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "HhaQozKlrnkC"
   },
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "summarize_prompt_template = \"\"\"\n",
    "You are a helpful assistant that summarizes AI concepts:\n",
    "{context}\n",
    "Summarize the context\n",
    "\"\"\"\n",
    "\n",
    "summarize_prompt = PromptTemplate.from_template(summarize_prompt_template)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "848txAD_o8kR",
    "outputId": "6ee322b3-d6de-4be2-aa23-f2904168301a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['context'], template='\\nYou are a helpful assistant that summarizes AI concepts:\\n{context}\\nSummarize the context\\n')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summarize_prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r264yXoiv7-O"
   },
   "source": [
    "### Create a Chain with the \"|\" operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 196
    },
    "id": "NPx6Qz_bTiwz",
    "outputId": "b89f15be-61e8-408b-8115-76ae6fef90af"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'LangChain is a decentralized artificial intelligence platform that aims to provide a marketplace for AI services and solutions. It allows developers to create, share, and monetize AI models and algorithms, while also enabling businesses to access a wide range of AI capabilities. The platform leverages blockchain technology to ensure transparency, security, and trust in the AI marketplace. Overall, LangChain seeks to democratize AI by making it more accessible and affordable for both developers and businesses.'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_parser = StrOutputParser()\n",
    "\n",
    "chain = summarize_prompt | llm_gpt4 | output_parser\n",
    "\n",
    "chain.invoke({\"context\": \"What is LangChain?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eW3dgnfXKU8r",
    "outputId": "e802cd49-00c6-41d7-e00d-cf672dd206ee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.runnables.base.RunnableSequence'>\n"
     ]
    }
   ],
   "source": [
    "# Verify the type of the chain\n",
    "print(type(chain)) # Should print <class 'langchain_core.runnables.base.RunnableSequence'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ke-ycihtrxpF"
   },
   "source": [
    "### Using a RunnableLambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "GEs1q_b6Kgs5",
    "outputId": "8fc65923-56e4-48ba-bd20-cd6da84f6c4b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Summary length: 574 characters'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inject python functions into a chain with RunnableLambda\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "\n",
    "summarize_chain = summarize_prompt | llm_gpt4 | output_parser\n",
    "\n",
    "# Define a custom lambda function and wrap it in RunnableLambda\n",
    "length_lambda = RunnableLambda(lambda summary: f\"Summary length: {len(summary)} characters\")\n",
    "\n",
    "lambda_chain = summarize_chain | length_lambda\n",
    "\n",
    "lambda_chain.invoke({\"context\": \"What is LangChain?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "R-OhiwW33iiU",
    "outputId": "f964f77a-1fba-494b-c4c8-0ebc58d7af23"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.runnables.base.RunnableLambda'>\n"
     ]
    }
   ],
   "source": [
    "print(type(lambda_chain.steps[-1])) # Should print <class 'langchain_core.runnables.base.RunnableLambda'>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "JI2Y4s7oUYOI"
   },
   "outputs": [],
   "source": [
    "# Use function in chain without converting to RunnableLambda\n",
    "chain_with_function = summarize_chain |  (lambda summary: f\"Summary length: {len(summary)} characters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iZgqYfgj3hS1",
    "outputId": "1236a785-66ac-498e-c673-4bc896ab04ea"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.runnables.base.RunnableLambda'>\n"
     ]
    }
   ],
   "source": [
    "print(type(chain_with_function.steps[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "Q3x7H60speRq",
    "outputId": "c4850466-076c-415e-ca29-eea529f6859b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Summary length: 425 characters'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain_with_function.invoke({\"context\": \"What is LangChain?\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "75J0BqR3uKpv"
   },
   "source": [
    "### RunnablePassthrough as placeholder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "p6rAREimtqLi",
    "outputId": "d241c57a-eb77-42d7-c67d-b270246bd7fb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Summary length: 514 characters'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "summarize_chain = summarize_prompt | llm_gpt4 | output_parser\n",
    "\n",
    "# Create a RunnablePassthrough instance\n",
    "passthrough = RunnablePassthrough()\n",
    "\n",
    "# Create the sequence using the pipe operator with summarization and length calculation\n",
    "placeholder_chain = summarize_chain| passthrough | length_lambda\n",
    "\n",
    "placeholder_chain.invoke({\"context\": \"What is LangChain?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_eZz4CEpviLa",
    "outputId": "5115c76b-9865-4e18-de30-210368e9d07b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.runnables.base.RunnableLambda'>\n",
      "<class 'langchain_core.runnables.passthrough.RunnablePassthrough'>\n"
     ]
    }
   ],
   "source": [
    "print(type(placeholder_chain.steps[-1]))  # Should print <class 'langchain_core.runnables.base.RunnableLambda'>\n",
    "print(type(placeholder_chain.steps[-2]))  # Should print <class 'langchain_core.runnables.passthrough.RunnablePassthrough'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Cc8VpIM4uQxw"
   },
   "source": [
    "### RunnablePassthrough for assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ITVOr1PJ9u5z",
    "outputId": "2c83f30c-c625-434b-e111-c3c6c2e867a2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'summary': 'LangChain is a decentralized platform that aims to bridge the gap between natural language processing (NLP) and blockchain technology. It allows developers to create and deploy NLP models on the blockchain, enabling secure and transparent processing of natural language data. This integration of NLP and blockchain technology has the potential to revolutionize various industries, such as finance, healthcare, and marketing, by providing more efficient and secure ways to analyze and utilize natural language data.',\n",
       " 'length': 514}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define a custom lambda function to wrap the summary in a dictionary\n",
    "wrap_summary_lambda = RunnableLambda(lambda summary: {\"summary\": summary})\n",
    "\n",
    "# Create a RunnablePassthrough instance that assigns additional information\n",
    "assign_passthrough = RunnablePassthrough.assign(length=lambda x: len(x[\"summary\"]))\n",
    "\n",
    "# Create the summarization chain\n",
    "summarize_chain = summarize_prompt | llm_gpt4 | output_parser | wrap_summary_lambda\n",
    "\n",
    "# Create the full chain combining summarization and assign_passthrough\n",
    "assign_chain = summarize_chain | assign_passthrough\n",
    "\n",
    "# Use the chain\n",
    "assign_chain.invoke({\"context\": \"What is LangChain?\"})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ilA-25jYaITV",
    "outputId": "8144ccae-ac62-4b0f-e54c-c728c212b4c9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.runnables.passthrough.RunnableAssign'>\n"
     ]
    }
   ],
   "source": [
    "print(type(assign_chain.steps[-1])) # Should print <class 'langchain_core.runnables.passthrough.RunnableAssign'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XhRfKg_Wws9N"
   },
   "source": [
    "### Using RunnableParallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Lwgwh2Czzx75",
    "outputId": "76d734a2-bf09-46f5-82e8-d0b46e8bf128"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'summary': 'LangChain is a decentralized platform that aims to provide a marketplace for language-related AI services. It allows users to access and utilize various language processing tools and services, such as translation, sentiment analysis, and natural language processing, through a blockchain-based system. This platform enables developers to create and deploy AI models for language-related tasks, while also providing a marketplace for users to access these services.',\n",
       " 'length': 464}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnableParallel\n",
    "\n",
    "# Create the summarization chain\n",
    "summarize_chain = summarize_prompt | llm_gpt4 | output_parser\n",
    "\n",
    "# Create a RunnableParallel instance to handle summary and length in parallel\n",
    "parallel_runnable = RunnableParallel(\n",
    "    summary=lambda x: x,  # Passes the summary as is\n",
    "    length=lambda x: len(x)  # Calculates the length of the summary\n",
    ")\n",
    "\n",
    "# Combine the summarization chain with parallel runnable\n",
    "parallel_chain = summarize_chain | parallel_runnable\n",
    "\n",
    "parallel_chain.invoke({\"context\": \"What is LangChain?\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2MSV99HovG1f",
    "outputId": "821b0c78-4b98-48ce-f62c-3030dcb98b4b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.runnables.base.RunnableParallel'>\n"
     ]
    }
   ],
   "source": [
    "# Verify the type of the last element in the chain\n",
    "print(type(parallel_chain.steps[-1]))  # Should print <class 'langchain_core.runnables.parallel.RunnableParallel'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2xnloFfrKdVm"
   },
   "source": [
    "## 4. Retrievers & Splitters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LtV7hn48HkHG",
    "outputId": "5c1025c1-b2c0-4aa1-89b8-035b09179d64"
   },
   "outputs": [],
   "source": [
    "! pip install --upgrade --quiet  redis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "F-16JiI-w-y0"
   },
   "outputs": [],
   "source": [
    "# Import the Youtube Loader from the LangChain community\n",
    "\n",
    "from langchain_community.document_loaders import YoutubeLoader\n",
    "\n",
    "loader = YoutubeLoader.from_youtube_url(\n",
    "    \"https://www.youtube.com/watch?v=AOEGOhkGtjI\", add_video_info=False\n",
    ")\n",
    "\n",
    "# Load the video transcript as documents\n",
    "docs=loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "u9oNaHe89j9j",
    "outputId": "7737661b-2063-4c95-c1e2-d47f1a197848"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'AOEGOhkGtjI'}, page_content=\"so now we have Lama 3 from meta and this model is definitely going to be a GameChanger when it comes to analyzing data with llms here I have L 3 on gr cloud and not only are the text to SQL chains blazing fast they're also capable of generating quite Advanced SQL and almost on par with the high IQ llms if we Implement one additional tweak so in this video I'm going to show you how we can tweak the SQL chains to maximize the performance of Lama 3 we're going to have a look at some of the insights that Lama three is capable of extracting and finally I'm going to briefly discuss some of the implications for llm based data analysis on l.a. comom you can read about Lama 3 and some of the capabilities of the model you can see how the model compares to other popular llms specifically the 70b model that I'm going to be using in this video is compared to Gemini and CLA 3 Sunnet and there's also a link that lets you request access to Lama 3 but this is not what I'll be doing I'm going to be using Gro Cloud because it's the fastest and easiest way to get started using llama 3 and as you can see the 70b model is already available on gr Cloud so I'll just grab the API key and then I'm ready to build the SQL chains with L chain all right the first thing I'm going to do is I'm going to set up the cop notebook and pip install the required libraries then I'll connect to Bay and fetch the schema information from tables in a data set I'll be installing python. EnV to fetch the API Keys Lang chain Gro the Lang chain Gro connector and Google Cloud B quy then I have uploaded myv file with the API keys I have my Google cloud service account key DBQ key. jjon then I have two functions that extracts the schema information from bit query in a schema. py file and this is the same functions that I've been using in the earlier videos that lets me extract and feed the scheme information from bitre to the chain all right so I'm just going to load the environment variables and then I'm going to connect to biy and the data set I'm using is the same data set I used in the last video in the dashboard video it is an e-commerce data set with four tables customers orders products and customer taxs and the two functions in the schema. py file allows me to extract the schema information from the data set as you can see here so now let's connect to Lama 3 on Gro cloud and set set up the SQL chain using Lang chain expression language to connect to Lama 3 on groc cloud we import chat Gro from Lang chain grock and then we instantiate it with a model name in this case I'm using Lama 370b and the prom template will be injecting three things first I'll inject the schema information I'm extracting from the bit crate data set then I'm injecting the main question or the query and finally I'll be injecting a a message history and the message history is The Tweak I mentioned in the beginning so I'm going to have Lama 3 generate SQL code and then I'll use the bitr client to execute that SQL code and if there's an error I'm going to catch the error and feed it back to the chain and this allows me to make the chains self-correcting which is useful when we're dealing with a model that is of a low IQ the SQL chain is assembled in the usual way I'll use a runnable path through to to inject the schema information and to inject the messages of the message history that contains the errors then I use my prompt the language model and a string output passer and this is what we need to generate the SQL code from a prompt now let's move on to generate some insights with this setup I had difficulties having Lama 3 return clean executable SQL so I had to write a function that lets me extract the SQL code from the response and in this extract SQL function I'm simply using regex to extract the SQL from whatever the language model is returning to wrap it all up I'm creating a function that takes a prompt and a number of attempts as input and then it will generate the SQL using the Lang chain SQL chain and try to execute that SQL up to five times and whenever there's an error I'm going to collect the error and feed it back to the chain and try again and in this way the chain will be self-corrected ing because the llm will understand the error message okay so let's try this the first prompt I'm going to give L three is the following give me a list of the best customers including their rank their first name last name and email and the products they purchased and this one it got in the first attempt so the query executed successfully and we can then have a look at the data frame and this is essentially an audience that you could use for marketing purposes you normally create an audience like this in a customer data platform now let's try a different one I'll do a classical one show me the revenue generated in the last 30 days broken down by acquisition Channel and here you can see that the first attempt is unsuccessful it fails but feeding back the error message makes the second attempt successful and here we have Revenue broken down by acquisition source let's do another audience let's say I want the top 100 customers with the highest purchase frequency but with an under average aov and again we see that the first attempt fails and the second attempt is successful and here we only got the names let's say that we want to include the frequency and the aov as well to get the full overview and here we see that the first attempt fails the second attempt also fails but the third attempt is a success and here we have the full audience data frame with the purchase frequency and the average order value so this is very useful so we can use llama 3 for generating insights if we just implement this small tweak of catching the errors and feeding it back to the chain all right so what are the implications of this first of all we now know that with Lama 3 open source llms can be used to generate insights and this is very good news for privacy sensitive use cases so use cases where you want to feed sensitive customer data back to the llm and in real sensitive use cases you probably don't want to use gr Cloud you want to use Lama 3 locally this is also very good news for query heavy applications so text tosql applications can be query heavy if they're rolled out in a big organization so there's a cost consideration that might be worth looking into now Gro cloud is all about realtime gen inference so Lama 3 on gr cloud is going to be really useful for Consumer facing applications where speed is necessary finally I think it's pretty clear now that data pipelines dashboards reports and so on will be llm generated in the future and not so distant future so if you are a data analyst or data engineer you should really pay attention to this and learn this new technology all right that's it for now if you enjoyed this video I suggest you check out one of the other videos on generating SQL with llm chains thanks for watching\")]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "-8_5WwpHDoFi"
   },
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "EMfIZb4YDoQJ"
   },
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=100,\n",
    "    chunk_overlap=20,\n",
    "    length_function=len,\n",
    "    is_separator_regex=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "FkKhVCMcDoXX"
   },
   "outputs": [],
   "source": [
    "docs_split = text_splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WFpE66iXDods",
    "outputId": "3871a215-c2ac-46a1-ee53-f5f3712dc493"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'AOEGOhkGtjI'}, page_content='so now we have Lama 3 from meta and this model is definitely going to be a GameChanger when it comes'),\n",
       " Document(metadata={'source': 'AOEGOhkGtjI'}, page_content='when it comes to analyzing data with llms here I have L 3 on gr cloud and not only are the text to'),\n",
       " Document(metadata={'source': 'AOEGOhkGtjI'}, page_content=\"are the text to SQL chains blazing fast they're also capable of generating quite Advanced SQL and\"),\n",
       " Document(metadata={'source': 'AOEGOhkGtjI'}, page_content='Advanced SQL and almost on par with the high IQ llms if we Implement one additional tweak so in'),\n",
       " Document(metadata={'source': 'AOEGOhkGtjI'}, page_content=\"tweak so in this video I'm going to show you how we can tweak the SQL chains to maximize the\"),\n",
       " Document(metadata={'source': 'AOEGOhkGtjI'}, page_content=\"to maximize the performance of Lama 3 we're going to have a look at some of the insights that Lama\"),\n",
       " Document(metadata={'source': 'AOEGOhkGtjI'}, page_content=\"insights that Lama three is capable of extracting and finally I'm going to briefly discuss some of\"),\n",
       " Document(metadata={'source': 'AOEGOhkGtjI'}, page_content='discuss some of the implications for llm based data analysis on l.a. comom you can read about Lama'),\n",
       " Document(metadata={'source': 'AOEGOhkGtjI'}, page_content='can read about Lama 3 and some of the capabilities of the model you can see how the model compares'),\n",
       " Document(metadata={'source': 'AOEGOhkGtjI'}, page_content=\"the model compares to other popular llms specifically the 70b model that I'm going to be using in\"),\n",
       " Document(metadata={'source': 'AOEGOhkGtjI'}, page_content=\"to be using in this video is compared to Gemini and CLA 3 Sunnet and there's also a link that lets\"),\n",
       " Document(metadata={'source': 'AOEGOhkGtjI'}, page_content=\"a link that lets you request access to Lama 3 but this is not what I'll be doing I'm going to be\"),\n",
       " Document(metadata={'source': 'AOEGOhkGtjI'}, page_content=\"I'm going to be using Gro Cloud because it's the fastest and easiest way to get started using llama\"),\n",
       " Document(metadata={'source': 'AOEGOhkGtjI'}, page_content=\"started using llama 3 and as you can see the 70b model is already available on gr Cloud so I'll\"),\n",
       " Document(metadata={'source': 'AOEGOhkGtjI'}, page_content=\"on gr Cloud so I'll just grab the API key and then I'm ready to build the SQL chains with L chain\"),\n",
       " Document(metadata={'source': 'AOEGOhkGtjI'}, page_content=\"chains with L chain all right the first thing I'm going to do is I'm going to set up the cop\"),\n",
       " Document(metadata={'source': 'AOEGOhkGtjI'}, page_content=\"to set up the cop notebook and pip install the required libraries then I'll connect to Bay and\"),\n",
       " Document(metadata={'source': 'AOEGOhkGtjI'}, page_content=\"connect to Bay and fetch the schema information from tables in a data set I'll be installing\"),\n",
       " Document(metadata={'source': 'AOEGOhkGtjI'}, page_content=\"I'll be installing python. EnV to fetch the API Keys Lang chain Gro the Lang chain Gro connector\"),\n",
       " Document(metadata={'source': 'AOEGOhkGtjI'}, page_content='chain Gro connector and Google Cloud B quy then I have uploaded myv file with the API keys I have'),\n",
       " Document(metadata={'source': 'AOEGOhkGtjI'}, page_content='the API keys I have my Google cloud service account key DBQ key. jjon then I have two functions'),\n",
       " Document(metadata={'source': 'AOEGOhkGtjI'}, page_content='have two functions that extracts the schema information from bit query in a schema. py file and'),\n",
       " Document(metadata={'source': 'AOEGOhkGtjI'}, page_content=\"schema. py file and this is the same functions that I've been using in the earlier videos that lets\"),\n",
       " Document(metadata={'source': 'AOEGOhkGtjI'}, page_content='videos that lets me extract and feed the scheme information from bitre to the chain all right so'),\n",
       " Document(metadata={'source': 'AOEGOhkGtjI'}, page_content=\"chain all right so I'm just going to load the environment variables and then I'm going to connect\"),\n",
       " Document(metadata={'source': 'AOEGOhkGtjI'}, page_content=\"going to connect to biy and the data set I'm using is the same data set I used in the last video in\"),\n",
       " Document(metadata={'source': 'AOEGOhkGtjI'}, page_content='the last video in the dashboard video it is an e-commerce data set with four tables customers'),\n",
       " Document(metadata={'source': 'AOEGOhkGtjI'}, page_content='tables customers orders products and customer taxs and the two functions in the schema. py file'),\n",
       " Document(metadata={'source': 'AOEGOhkGtjI'}, page_content='the schema. py file allows me to extract the schema information from the data set as you can see'),\n",
       " Document(metadata={'source': 'AOEGOhkGtjI'}, page_content=\"set as you can see here so now let's connect to Lama 3 on Gro cloud and set set up the SQL chain\"),\n",
       " Document(metadata={'source': 'AOEGOhkGtjI'}, page_content='up the SQL chain using Lang chain expression language to connect to Lama 3 on groc cloud we import'),\n",
       " Document(metadata={'source': 'AOEGOhkGtjI'}, page_content='cloud we import chat Gro from Lang chain grock and then we instantiate it with a model name in this'),\n",
       " Document(metadata={'source': 'AOEGOhkGtjI'}, page_content=\"model name in this case I'm using Lama 370b and the prom template will be injecting three things\"),\n",
       " Document(metadata={'source': 'AOEGOhkGtjI'}, page_content=\"three things first I'll inject the schema information I'm extracting from the bit crate data set\"),\n",
       " Document(metadata={'source': 'AOEGOhkGtjI'}, page_content=\"bit crate data set then I'm injecting the main question or the query and finally I'll be injecting\"),\n",
       " Document(metadata={'source': 'AOEGOhkGtjI'}, page_content=\"I'll be injecting a a message history and the message history is The Tweak I mentioned in the\"),\n",
       " Document(metadata={'source': 'AOEGOhkGtjI'}, page_content=\"I mentioned in the beginning so I'm going to have Lama 3 generate SQL code and then I'll use the\"),\n",
       " Document(metadata={'source': 'AOEGOhkGtjI'}, page_content=\"then I'll use the bitr client to execute that SQL code and if there's an error I'm going to catch\"),\n",
       " Document(metadata={'source': 'AOEGOhkGtjI'}, page_content=\"I'm going to catch the error and feed it back to the chain and this allows me to make the chains\"),\n",
       " Document(metadata={'source': 'AOEGOhkGtjI'}, page_content=\"to make the chains self-correcting which is useful when we're dealing with a model that is of a low\"),\n",
       " Document(metadata={'source': 'AOEGOhkGtjI'}, page_content=\"that is of a low IQ the SQL chain is assembled in the usual way I'll use a runnable path through to\"),\n",
       " Document(metadata={'source': 'AOEGOhkGtjI'}, page_content='path through to to inject the schema information and to inject the messages of the message history'),\n",
       " Document(metadata={'source': 'AOEGOhkGtjI'}, page_content='the message history that contains the errors then I use my prompt the language model and a string'),\n",
       " Document(metadata={'source': 'AOEGOhkGtjI'}, page_content='model and a string output passer and this is what we need to generate the SQL code from a prompt'),\n",
       " Document(metadata={'source': 'AOEGOhkGtjI'}, page_content=\"code from a prompt now let's move on to generate some insights with this setup I had difficulties\"),\n",
       " Document(metadata={'source': 'AOEGOhkGtjI'}, page_content='I had difficulties having Lama 3 return clean executable SQL so I had to write a function that lets'),\n",
       " Document(metadata={'source': 'AOEGOhkGtjI'}, page_content=\"function that lets me extract the SQL code from the response and in this extract SQL function I'm\"),\n",
       " Document(metadata={'source': 'AOEGOhkGtjI'}, page_content=\"SQL function I'm simply using regex to extract the SQL from whatever the language model is\"),\n",
       " Document(metadata={'source': 'AOEGOhkGtjI'}, page_content=\"language model is returning to wrap it all up I'm creating a function that takes a prompt and a\"),\n",
       " Document(metadata={'source': 'AOEGOhkGtjI'}, page_content='a prompt and a number of attempts as input and then it will generate the SQL using the Lang chain'),\n",
       " Document(metadata={'source': 'AOEGOhkGtjI'}, page_content=\"the Lang chain SQL chain and try to execute that SQL up to five times and whenever there's an error\"),\n",
       " Document(metadata={'source': 'AOEGOhkGtjI'}, page_content=\"there's an error I'm going to collect the error and feed it back to the chain and try again and in\"),\n",
       " Document(metadata={'source': 'AOEGOhkGtjI'}, page_content='try again and in this way the chain will be self-corrected ing because the llm will understand the'),\n",
       " Document(metadata={'source': 'AOEGOhkGtjI'}, page_content=\"will understand the error message okay so let's try this the first prompt I'm going to give L three\"),\n",
       " Document(metadata={'source': 'AOEGOhkGtjI'}, page_content='to give L three is the following give me a list of the best customers including their rank their'),\n",
       " Document(metadata={'source': 'AOEGOhkGtjI'}, page_content='their rank their first name last name and email and the products they purchased and this one it got'),\n",
       " Document(metadata={'source': 'AOEGOhkGtjI'}, page_content='and this one it got in the first attempt so the query executed successfully and we can then have a'),\n",
       " Document(metadata={'source': 'AOEGOhkGtjI'}, page_content='we can then have a look at the data frame and this is essentially an audience that you could use'),\n",
       " Document(metadata={'source': 'AOEGOhkGtjI'}, page_content='that you could use for marketing purposes you normally create an audience like this in a customer'),\n",
       " Document(metadata={'source': 'AOEGOhkGtjI'}, page_content=\"this in a customer data platform now let's try a different one I'll do a classical one show me the\"),\n",
       " Document(metadata={'source': 'AOEGOhkGtjI'}, page_content='one show me the revenue generated in the last 30 days broken down by acquisition Channel and here'),\n",
       " Document(metadata={'source': 'AOEGOhkGtjI'}, page_content='Channel and here you can see that the first attempt is unsuccessful it fails but feeding back the'),\n",
       " Document(metadata={'source': 'AOEGOhkGtjI'}, page_content='feeding back the error message makes the second attempt successful and here we have Revenue broken'),\n",
       " Document(metadata={'source': 'AOEGOhkGtjI'}, page_content=\"have Revenue broken down by acquisition source let's do another audience let's say I want the top\"),\n",
       " Document(metadata={'source': 'AOEGOhkGtjI'}, page_content='say I want the top 100 customers with the highest purchase frequency but with an under average aov'),\n",
       " Document(metadata={'source': 'AOEGOhkGtjI'}, page_content='under average aov and again we see that the first attempt fails and the second attempt is'),\n",
       " Document(metadata={'source': 'AOEGOhkGtjI'}, page_content=\"second attempt is successful and here we only got the names let's say that we want to include the\"),\n",
       " Document(metadata={'source': 'AOEGOhkGtjI'}, page_content='want to include the frequency and the aov as well to get the full overview and here we see that the'),\n",
       " Document(metadata={'source': 'AOEGOhkGtjI'}, page_content='we see that the first attempt fails the second attempt also fails but the third attempt is a'),\n",
       " Document(metadata={'source': 'AOEGOhkGtjI'}, page_content='third attempt is a success and here we have the full audience data frame with the purchase'),\n",
       " Document(metadata={'source': 'AOEGOhkGtjI'}, page_content='with the purchase frequency and the average order value so this is very useful so we can use llama'),\n",
       " Document(metadata={'source': 'AOEGOhkGtjI'}, page_content='so we can use llama 3 for generating insights if we just implement this small tweak of catching the'),\n",
       " Document(metadata={'source': 'AOEGOhkGtjI'}, page_content='of catching the errors and feeding it back to the chain all right so what are the implications of'),\n",
       " Document(metadata={'source': 'AOEGOhkGtjI'}, page_content='the implications of this first of all we now know that with Lama 3 open source llms can be used to'),\n",
       " Document(metadata={'source': 'AOEGOhkGtjI'}, page_content='llms can be used to generate insights and this is very good news for privacy sensitive use cases so'),\n",
       " Document(metadata={'source': 'AOEGOhkGtjI'}, page_content='use cases so use cases where you want to feed sensitive customer data back to the llm and in real'),\n",
       " Document(metadata={'source': 'AOEGOhkGtjI'}, page_content=\"the llm and in real sensitive use cases you probably don't want to use gr Cloud you want to use\"),\n",
       " Document(metadata={'source': 'AOEGOhkGtjI'}, page_content='you want to use Lama 3 locally this is also very good news for query heavy applications so text'),\n",
       " Document(metadata={'source': 'AOEGOhkGtjI'}, page_content=\"so text tosql applications can be query heavy if they're rolled out in a big organization so\"),\n",
       " Document(metadata={'source': 'AOEGOhkGtjI'}, page_content=\"big organization so there's a cost consideration that might be worth looking into now Gro cloud is\"),\n",
       " Document(metadata={'source': 'AOEGOhkGtjI'}, page_content='now Gro cloud is all about realtime gen inference so Lama 3 on gr cloud is going to be really'),\n",
       " Document(metadata={'source': 'AOEGOhkGtjI'}, page_content='going to be really useful for Consumer facing applications where speed is necessary finally I think'),\n",
       " Document(metadata={'source': 'AOEGOhkGtjI'}, page_content=\"finally I think it's pretty clear now that data pipelines dashboards reports and so on will be llm\"),\n",
       " Document(metadata={'source': 'AOEGOhkGtjI'}, page_content='so on will be llm generated in the future and not so distant future so if you are a data analyst or'),\n",
       " Document(metadata={'source': 'AOEGOhkGtjI'}, page_content='a data analyst or data engineer you should really pay attention to this and learn this new'),\n",
       " Document(metadata={'source': 'AOEGOhkGtjI'}, page_content=\"and learn this new technology all right that's it for now if you enjoyed this video I suggest you\"),\n",
       " Document(metadata={'source': 'AOEGOhkGtjI'}, page_content='video I suggest you check out one of the other videos on generating SQL with llm chains thanks for'),\n",
       " Document(metadata={'source': 'AOEGOhkGtjI'}, page_content='chains thanks for watching')]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5yQG7bkSHBGl"
   },
   "outputs": [],
   "source": [
    "REDIS_URL=\"redis://default:your_redis_password@your_redis_host:your_redis_port\"\n",
    "REDIS_HOST=\"your_redis_host\"\n",
    "REDIS_PASSWORD=\"your_redis_password\"\n",
    "REDIS_PORT=\"your_redis_port\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sZoU-4ucDojx"
   },
   "outputs": [],
   "source": [
    "import redis\n",
    "\n",
    "r = redis.Redis(\n",
    "  host=REDIS_HOST,\n",
    "  port=REDIS_PORT,\n",
    "  password=REDIS_PASSWORD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_U_pMl4WDopo",
    "outputId": "42687bd8-ba86-423a-c297-1a947730f0e9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.ping()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7ACoTRLuL5CU",
    "outputId": "79eb7b16-423a-4d69-9f88-2ce1d6a5dff4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.flushdb()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ls9EpiPnyNJ4",
    "outputId": "3fa867a9-d390-42bd-cfca-176c46aa8cdc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m227.1/227.1 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m50.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "! pip install --upgrade --quiet sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 603,
     "referenced_widgets": [
      "084a0038b5ec449297460deec481693c",
      "fb1bc3b542e742a787ac8cdd8b794600",
      "a37869d5478f4b2f82125c9785b9b436",
      "032a03aeee124c3e9a9950df4b3ef432",
      "91bb089964f94d2c94f2bc7533c8e25b",
      "aac2173b7cda4fcfa9e99a630aeb29ac",
      "2dc45170227d47e08fdcc4b7cf4b20c0",
      "61691b5d18fc44ecacda46b88f874cc4",
      "d9c4e126c8b14f5e9ce4303fcaa54e09",
      "dff85f8149674f459b89803fc7153e3e",
      "464269e3d6ca4c5d8211cf2084d2d17e",
      "fd07a7b9f1b1409ebd3f660f0518e758",
      "6b74b2095f564ac78f26ead3ec868d4d",
      "ae04ebe295e34373b74faf3ec1bb2cfa",
      "6c3e6d030a1a4993a812e128cd1cb56d",
      "43b529058903409d99e81f4a33b491f5",
      "a8f60727d06645bbb2f623ebd2db114a",
      "dbb5c0fd46194d0594d385e8d60cccb3",
      "87445bf1b2654d06aae01ac0ed454ad9",
      "f79fc34cf7914438a17fc10e8185bf10",
      "27b01b2b7e704244afdfb95645db9a71",
      "ebf599bae0a64054ae1314c4b1469701",
      "6bd138a3e01640e997810f9b71264c47",
      "06208b7d09b44c4894d61eea32db0b82",
      "ebbd4cbedf664d168116b13629478f4c",
      "19ff658c4aa14f0f8c623bf87552eb47",
      "9c184e70490e4f4b8e620774736de029",
      "19d030715ed44f2cb0aa3c46dcf78156",
      "67571c30f4da4e9095c5ebe5dd05ac1f",
      "83d97561ad2844f6a44ecdb5099cc1e9",
      "2c8197a5208b46e8a7be9eb622f61c93",
      "27dd7624edc644e48c7a245c90dbe46c",
      "67120da8875c492bbfdff8fb995bdb56",
      "eddd05e7269c41af98b12f260425e834",
      "035b4ae8f52e4108b7f9954592d69e2c",
      "fcb9ac37f7dc4ec2992275c805a86b4b",
      "892b052e040b4e318f05812d82691d46",
      "0100d6760bc543afa6059631e937af2f",
      "0ace348c6e3a4100bf2e113d4c41ee86",
      "e368661e1682492b82023b9cc9a98a99",
      "8d370ca4226f436dae3c5e85549ad5f7",
      "12f6319c71b8490fbf6df0b3bf5ead4d",
      "367d9496c40542818869ca70c201776c",
      "a9eeab3b052b466a9f62e9ae6b4b91a6",
      "a974d3f931ca48c8bcab79b4d639cb76",
      "76c33f0733aa41cf9a00a417867dd2f2",
      "5b9bb6dddff44a64aed0c4bb9238f551",
      "eb824d8ec7b44726af215fdc8be40813",
      "99bc5473f32c48cab946c7a6033b6c2a",
      "145cf50f6cab4b158d2080ce60059ee0",
      "bfaa0777dc214b45843bf9ec431b3748",
      "b69bdda9bec24b22a027d77565130704",
      "270990277966485eb20a9ae97c1f376d",
      "44a8073da9cd40a588a02c3df2de2665",
      "8a77b322c3e44307821d9fded2e3c25c",
      "e6b3b724429b47869397453137a0faca",
      "cb23c3e448494d6c91cc15a0d4b6dbbc",
      "417145bfcaa846d2b5242bce340e714d",
      "a0c615986d944a9cb60836ab3ba3f563",
      "73475bbb3fd949ab9ce9cffb4e6157a2",
      "f5ed01e00cf04185871747df0826cb16",
      "5fe0f3049c794d1881a1336dbff1bcd0",
      "07bcf47ccd984238a55453d229ba9336",
      "69ff32abfb1d49b58a04519d9e445e02",
      "478a39d31ab54a9eb58a7279d174eecb",
      "e5d9f0e7a8bf4629958b30d36efeb0cd",
      "a30d8a3c02c940c69aaeaf9cc5d46848",
      "008b7d227ee1443b970bfb176cd5b2b5",
      "8bedbdf27f4a444489a9941ca9c9c4a3",
      "39e9f2d982c54eb39f62927deeda57c4",
      "a8b807b24ab6455faf60499936d126d5",
      "a12db68ee6dc472eb02dca08c420f9f3",
      "fae25eac95f0409fa1a75ca8be69147c",
      "e7889bf0482d485c9c2bfd48ce12e666",
      "2ab25e703d944cf6bd57d23dddbee25c",
      "17725872d9b14c1ca7be6d42f93e2811",
      "e1b1425d29c046149b5b7dd43e17b45b",
      "e20c8adfc1ea448ea770b476a0b8e1a4",
      "db8cf6a511c84896940e7e7a03d5a866",
      "79a3336be19b4d6988cf784c89b119d8",
      "fbb977bfbbe149858563e29a346380fe",
      "f8e39202a22a4f01bacc6d16efc180e2",
      "7ceadc92017d401496635b5b281c925e",
      "879cd0a6d3014bb9805bbdbfe8794487",
      "b4dc1fb6b1dc45139f921563edeea9c7",
      "f89db308102e40439188ab6500709be5",
      "d0084d02f18d4f8d881f8681b7660e3a",
      "df213338b072434aa2ced9908d0ba3c0",
      "898e547bb7b9493c99c2ecbec75146bc",
      "0d1f76e36d834e65bb7425a7205ee7f7",
      "0ded6b95cb3c40559927e77260caa4c3",
      "cc52b15aa02b488085adbb45bed5a43f",
      "dcd017f5203640488bffc293dfa061c6",
      "029f8e5b75b04fbe9a5ad1658a6557aa",
      "7a2257fb33e34d69b960d2636cab3b33",
      "104b82369cd646fe9b04f78ecac6b09c",
      "5fe5a6d57e494914987ebf8ca2640d43",
      "d023080eec2547029bf38facff69a6b9",
      "c616faf23fa14d598d8fd15cc2866d58",
      "cbe03d7dda4f4912b8db418e14f444f2",
      "aeda4b1d6ac246e686813fbee185d39b",
      "5b5c2b418af04548ab93918fb26c1620",
      "5bbcba16869042f795f0e78d3cd5e39e",
      "464872045ebc41cdacd5cf89ac591bd6",
      "3acd5c289e2b4839b92a99457c0197a3",
      "49b9303aff0a4d26a7897850223221b3",
      "550af51366264da6bc279e67ad82f94d",
      "e246a6a64a774aaa8de93ae6dc7ae96c",
      "d521a1a4b35a4a2eba84c37fb376b7ad",
      "d2a49bef5cf24039b7a9e62b1642c1b3",
      "ef324189b1844b15b711bca7f023007c",
      "1d0a797258e24930bf8569ceb0ebeab0",
      "48bb0a3f7c2c4bc285b6763313eda159",
      "6ed5b15e9cb64600a0a33ac01eb2a656",
      "7619b5e38a83414b81c27d924571581b",
      "da6cbd2764fa4fc68ae84426725a8625",
      "927e2ba32d7a4573a19d724dbc87b74a",
      "27e4335a16574eaea7084db58ff7ea3f",
      "ac06bdf136ba40da933ba9fbdaeb72d9",
      "286ee328f3ca44a583e4a6e17a7a9a22",
      "1fedf56b3bba42a589e37c0452797320"
     ]
    },
    "id": "GnHpNle6Dou1",
    "outputId": "831e3ca2-e5f5-4eea-cae7-2adb71e6174c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:139: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 0.3.0. An updated version of the class exists in the langchain-huggingface package and should be used instead. To use it run `pip install -U langchain-huggingface` and import as `from langchain_huggingface import HuggingFaceEmbeddings`.\n",
      "  warn_deprecated(\n",
      "/usr/local/lib/python3.10/dist-packages/sentence_transformers/cross_encoder/CrossEncoder.py:11: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm, trange\n",
      "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "084a0038b5ec449297460deec481693c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd07a7b9f1b1409ebd3f660f0518e758",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6bd138a3e01640e997810f9b71264c47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/10.6k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eddd05e7269c41af98b12f260425e834",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a974d3f931ca48c8bcab79b4d639cb76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/571 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6b3b724429b47869397453137a0faca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/438M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a30d8a3c02c940c69aaeaf9cc5d46848",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/363 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e20c8adfc1ea448ea770b476a0b8e1a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "898e547bb7b9493c99c2ecbec75146bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbe03d7dda4f4912b8db418e14f444f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef324189b1844b15b711bca7f023007c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "1_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "embeddings = HuggingFaceEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x5qTlARpzlAs"
   },
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores.redis import Redis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hFrAYl_jDozt"
   },
   "outputs": [],
   "source": [
    "rds = Redis.from_documents(\n",
    "    docs_split,\n",
    "    embeddings,\n",
    "    redis_url=REDIS_URL,\n",
    "    index_name=\"youtube\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "mYvYqn8cDo4o",
    "outputId": "2df9b38b-e306-453f-a167-825daec88f4a"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'youtube'"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rds.index_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3HoxzPQrzs6D"
   },
   "outputs": [],
   "source": [
    "retriever = rds.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 10})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wnZ0mvWkzws1",
    "outputId": "aafab178-9c95-42db-fef4-b4973f93cecd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content=\"this in a customer data platform now let's try a different one I'll do a classical one show me the\", metadata={'id': 'doc:youtube:88cdceef33e34f4e8fa968c2a2799268', 'source': 'AOEGOhkGtjI'}),\n",
       " Document(page_content='a data analyst or data engineer you should really pay attention to this and learn this new', metadata={'id': 'doc:youtube:5f1ab6946b7944c8b4315ab037cadc29', 'source': 'AOEGOhkGtjI'}),\n",
       " Document(page_content='we can then have a look at the data frame and this is essentially an audience that you could use', metadata={'id': 'doc:youtube:89b61c7a1aee408097b69dab48646fcc', 'source': 'AOEGOhkGtjI'}),\n",
       " Document(page_content='discuss some of the implications for llm based data analysis on l.a. comom you can read about Lama', metadata={'id': 'doc:youtube:3ea23e317cc94967a803649c70079036', 'source': 'AOEGOhkGtjI'}),\n",
       " Document(page_content='the last video in the dashboard video it is an e-commerce data set with four tables customers', metadata={'id': 'doc:youtube:ce80ceb11a1b489c9fb243fdc85060be', 'source': 'AOEGOhkGtjI'}),\n",
       " Document(page_content=\"going to connect to biy and the data set I'm using is the same data set I used in the last video in\", metadata={'id': 'doc:youtube:0d3fab2e29de47dba829baf4086e47b9', 'source': 'AOEGOhkGtjI'}),\n",
       " Document(page_content='with the purchase frequency and the average order value so this is very useful so we can use llama', metadata={'id': 'doc:youtube:4a7e51380aa94142b9d44e3114e73ead', 'source': 'AOEGOhkGtjI'}),\n",
       " Document(page_content='to give L three is the following give me a list of the best customers including their rank their', metadata={'id': 'doc:youtube:74e4014d3aaa4556911fbabff033e4d4', 'source': 'AOEGOhkGtjI'}),\n",
       " Document(page_content='when it comes to analyzing data with llms here I have L 3 on gr cloud and not only are the text to', metadata={'id': 'doc:youtube:79159f2c370345afa16c7c55621f5fc1', 'source': 'AOEGOhkGtjI'}),\n",
       " Document(page_content=\"bit crate data set then I'm injecting the main question or the query and finally I'll be injecting\", metadata={'id': 'doc:youtube:c72da4716e764a11932300bf7e2b69f3', 'source': 'AOEGOhkGtjI'})]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever.invoke(\"data analysis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kjRvkiDLKjIA"
   },
   "source": [
    "## 5. Building a RAG Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dUPzEJYIw_h7"
   },
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "template = \"\"\"Answer the question based only on the following context:\n",
    "{context}\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "r6sZGnaMR7tS"
   },
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "output_parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hhK2JQjgICGX"
   },
   "outputs": [],
   "source": [
    "chain = (\n",
    "    {\"context\": (lambda x: x[\"question\"]) | retriever,\n",
    "     \"question\": (lambda x: x[\"question\"])}\n",
    "    | prompt\n",
    "    | llm_gpt4\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gV2K6pb1R-0e"
   },
   "outputs": [],
   "source": [
    "answer=chain.invoke({\"question\":\"What can you do with LLama 3?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "id": "EmMcbpIbBpFN",
    "outputId": "40c73f21-608d-4d54-e45e-30b3fedf5e2b"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'With Llama 3, you can generate insights, analyze data, and compare model capabilities. It is also noted that it can be used on Gro Cloud, which is described as the fastest and easiest way to get started with Llama 3.'"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GIj3mBUBKlmw"
   },
   "source": [
    "## 6. Chain with a Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "id": "y0D6VWq9L23L"
   },
   "outputs": [],
   "source": [
    "! pip install --upgrade --quiet  youtube_search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "zWo5gjMCLeIh"
   },
   "outputs": [],
   "source": [
    "from langchain_community.tools import YouTubeSearchTool\n",
    "\n",
    "youtube_tool = YouTubeSearchTool()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "YouTubeSearchTool()"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "YouTubeSearchTool()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "YouTubeSearchTool()"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "youtube_tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "id": "mGhA0oZ1Ngav",
    "outputId": "ff8a9351-9023-4d86-c807-ef4e9cb8c12e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"['https://www.youtube.com/watch?v=AOEGOhkGtjI&pp=ygUNUmFiYml0bWV0cmljcw%3D%3D', 'https://www.youtube.com/watch?v=X3ig10tKxPA&pp=ygUNUmFiYml0bWV0cmljcw%3D%3D']\""
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "youtube_tool.run(\"Rabbitmetrics\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "gTwJjbupMZma"
   },
   "outputs": [],
   "source": [
    "# Bind the YouTube tool to the LLM\n",
    "llm_with_tools = llm_gpt4.bind_tools([youtube_tool])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "IP2vlJ0B0uDW"
   },
   "outputs": [],
   "source": [
    "msg =llm_with_tools.invoke(\"Rabbtimetrics YT videos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Sfiebl0C23B0",
    "outputId": "1d97a373-0989-4f30-fff2-abd72cd97066"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'youtube_search',\n",
       "  'args': {'__arg1': 'Rabbtimetrics'},\n",
       "  'id': 'call_o9Kxfh6NHS1JdMbmXonOBcP4',\n",
       "  'type': 'tool_call'}]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "msg.tool_calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "D_yIhFdN04rF"
   },
   "outputs": [],
   "source": [
    "chain=llm_with_tools | (lambda x: x.tool_calls[0][\"args\"][\"__arg1\"]) | youtube_tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "id": "nWOPj_Sj05dU",
    "outputId": "264e8e4a-4d94-48a9-fbd5-fa08e32561f2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"['https://www.youtube.com/watch?v=aywZrzNaKjs&pp=ygUXUmFiYml0bWV0cmljcyBsYW5nY2hhaW4%3D', 'https://www.youtube.com/watch?v=Xi9Ui-9qcPw&pp=ygUXUmFiYml0bWV0cmljcyBsYW5nY2hhaW4%3D', 'https://www.youtube.com/watch?v=UO699Szp82M&pp=ygUXUmFiYml0bWV0cmljcyBsYW5nY2hhaW4%3D', 'https://www.youtube.com/watch?v=6sZqtp9f7VM&pp=ygUXUmFiYml0bWV0cmljcyBsYW5nY2hhaW4%3D', 'https://www.youtube.com/watch?v=MXhfLUoIRno&pp=ygUXUmFiYml0bWV0cmljcyBsYW5nY2hhaW4%3D']\""
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(\"Find some Rabbitmetrics videos on langchain\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "t-kXo30UTk_x"
   },
   "outputs": [],
   "source": [
    "msg =llm_with_tools.invoke(\"Rabbtimetrics YT videos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qg1pvZysT2Ra",
    "outputId": "37189afa-3616-45f5-9b7b-3e551337b177"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'youtube_search',\n",
       "  'args': {'__arg1': 'Rabbtimetrics,5'},\n",
       "  'id': 'call_9vNZz65PaplJqJGZYuoZiuya',\n",
       "  'type': 'tool_call'}]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "msg.tool_calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "JbJQ2DSaUCdg"
   },
   "outputs": [],
   "source": [
    "chain=llm_with_tools | (lambda x: x.tool_calls[0][\"args\"][\"__arg1\"]) | youtube_tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "id": "XWoXqKDiUaAa",
    "outputId": "77982261-1b98-4539-a65c-64aed580476d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"['https://www.youtube.com/watch?v=aywZrzNaKjs&pp=ygUXUmFiYml0bWV0cmljcyBsYW5nY2hhaW4%3D', 'https://www.youtube.com/watch?v=8BV9TW490nQ&pp=ygUXUmFiYml0bWV0cmljcyBsYW5nY2hhaW4%3D', 'https://www.youtube.com/watch?v=Xi9Ui-9qcPw&pp=ygUXUmFiYml0bWV0cmljcyBsYW5nY2hhaW4%3D', 'https://www.youtube.com/watch?v=UO699Szp82M&pp=ygUXUmFiYml0bWV0cmljcyBsYW5nY2hhaW4%3D', 'https://www.youtube.com/watch?v=6sZqtp9f7VM&pp=ygUXUmFiYml0bWV0cmljcyBsYW5nY2hhaW4%3D']\""
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(\"Find some Rabbitmetrics videos on langchain\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rpsmuB_gK0n7"
   },
   "source": [
    "## 7. Building an Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "id": "uiEjdI__2svv"
   },
   "outputs": [],
   "source": [
    "! pip install --upgrade --quiet langchainhub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "uCltklw7kYgX"
   },
   "outputs": [],
   "source": [
    "from langchain import hub\n",
    "from langchain.agents import AgentExecutor, create_tool_calling_agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-rbELzaL-6nh",
    "outputId": "0780b3a3-2deb-4fc9-869f-8cf60345d508"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template='You are a helpful assistant')),\n",
       " MessagesPlaceholder(variable_name='chat_history', optional=True),\n",
       " HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], template='{input}')),\n",
       " MessagesPlaceholder(variable_name='agent_scratchpad')]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = hub.pull(\"hwchase17/openai-tools-agent\")\n",
    "prompt.messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "id": "qQ0Gzyrn_ASh"
   },
   "outputs": [],
   "source": [
    "tools=[youtube_tool]\n",
    "\n",
    "agent = create_tool_calling_agent(llm_gpt4, tools, prompt)\n",
    "\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "z_rHfeiD_Ana",
    "outputId": "b2fc358f-63d8-4d13-d58b-103c213c24ca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `youtube_search` with `langchain`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m['https://www.youtube.com/watch?v=GoSbWL0_eGI&pp=ygUJbGFuZ2NoYWlu', 'https://www.youtube.com/watch?v=aywZrzNaKjs&pp=ygUJbGFuZ2NoYWlu']\u001b[0m\u001b[32;1m\u001b[1;3mI found some Langchain YouTube videos for you:\n",
      "1. [Langchain - The Future of Language Learning](https://www.youtube.com/watch?v=GoSbWL0_eGI&pp=ygUJbGFuZ2NoYWlu)\n",
      "2. [Langchain - The Future of Language Learning (Part 2)](https://www.youtube.com/watch?v=aywZrzNaKjs&pp=ygUJbGFuZ2NoYWlu)\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'Find some langchain YT videos',\n",
       " 'output': 'I found some Langchain YouTube videos for you:\\n1. [Langchain - The Future of Language Learning](https://www.youtube.com/watch?v=GoSbWL0_eGI&pp=ygUJbGFuZ2NoYWlu)\\n2. [Langchain - The Future of Language Learning (Part 2)](https://www.youtube.com/watch?v=aywZrzNaKjs&pp=ygUJbGFuZ2NoYWlu)'}"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.invoke(\n",
    "    {\n",
    "        \"input\": \"Find some langchain YT videos\"\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "hB70blASlbo6"
   },
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "\n",
    "@tool\n",
    "def transcribe_video(video_url:str) -> str:\n",
    "    \"Extract transcript from YT video\"\n",
    "    loader = YoutubeLoader.from_youtube_url(\n",
    "    video_url, add_video_info=False\n",
    "    )\n",
    "    docs=loader.load()\n",
    "    return docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "id": "obRRy20nmLm9"
   },
   "outputs": [],
   "source": [
    "tools = [youtube_tool, transcribe_video]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "id": "akG5YMcMmYmG"
   },
   "outputs": [],
   "source": [
    "\n",
    "agent = create_tool_calling_agent(llm_gpt4, tools, prompt)\n",
    "\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Jc8VvpW8mfXi",
    "outputId": "7e213702-62ba-4c0b-ec7e-5b8029b1d4f1"
   },
   "outputs": [],
   "source": [
    "agent_executor.invoke(\n",
    "    {\n",
    "        \"input\": \"What topics does the rabbitmetrics YT channel cover?\"\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0zHMz8pmmpqT"
   },
   "source": [
    "## 8. Colorina"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url = 'https://dashboard.colorines.paitesting.com/api'\n",
    "\n",
    "# Set the URL for the token API\n",
    "url_token = base_url+\"/v1/token\"\n",
    "\n",
    "# Set the data for the POST request\n",
    "data = {\n",
    "    \"email\": \"sale@platform.com\",\n",
    "    \"password\": os.getenv('CONSULTANT_PASSWORD'),\n",
    "    \"device_name\": \"colorina_2\",\n",
    "    \"role\": \"consultant\"\n",
    "}\n",
    "\n",
    "# Send a POST request\n",
    "response = requests.post(url_token, json=data)\n",
    "\n",
    "#print(response)\n",
    "\n",
    "# Extract the token from the response\n",
    "token = response.json().get('data').get('token')\n",
    "\n",
    "#print(\"Token:\", token)\n",
    "token_str = f\"auth token: {token}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def count_sales_by_status(token: str, status: str)-> int:\n",
    "    \"\"\"\n",
    "    Count the number of sales the user has with a specific status.\n",
    "    \n",
    "    \n",
    "    Args:\n",
    "        token (str): The authorization token required to access the API.\n",
    "        status (str): The status to filter the API request. Acceptable status by the API: reserved, documents, contract, active, canceled, overdue, finalized, deeded.\n",
    "\n",
    "    Returns:\n",
    "        int: The number of sales with the requested status.\n",
    "    \"\"\"\n",
    "    \n",
    "    df = GetSales(token=token, status=status)\n",
    "    count = len(df)\n",
    "    return count\n",
    "\n",
    "@tool\n",
    "def get_sales_by_customer(token: str, email: str) -> str:\n",
    "    \"\"\"\n",
    "    Retrieves and returns a list of sales associated with a customer identified by their email.\n",
    "\n",
    "    This function performs the following steps:\n",
    "    1. Uses the provided email to search for the customer ID.\n",
    "    2. Retrieves the sales attached to that customer ID.\n",
    "    3. Returns relevant sales information in JSON format.\n",
    "\n",
    "    Args:\n",
    "        token (str): The authorization token required to access the API.\n",
    "        email (str): The email address used to identify the customer.\n",
    "\n",
    "    Returns:\n",
    "        str: A JSON response containing information about sales made to the customer.\n",
    "             The JSON includes details about each sale that will be listed to the user by the agent.\n",
    "    \"\"\"\n",
    "    # Function implementation here\n",
    "    customers = GetCustomers(token)\n",
    "    customer_id = GetCustomerID(customers, email=email)\n",
    "    if customer_id:\n",
    "        df = GetSales(token=token, customer_id=customer_id)\n",
    "        df = PreprocessSales(df)\n",
    "        return CleanSalesByCustomer(df)\n",
    "    else:\n",
    "        return 'No se encontr ningn cliente con ese correo electrnico, pregunta al cliente si el correo es correcto'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_str='cuantas ventas tengo en estado de documentos?'\n",
    "input_data = f\"{input_str}. token: {token}\"\n",
    "\n",
    "# Bind the YouTube tool to the LLM\n",
    "llm_with_tools = llm_gpt4.bind_tools([count_sales_by_status, get_sales_by_customer])\n",
    "msg =llm_with_tools.invoke(input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'count_sales_by_status',\n",
       "  'args': {'token': '2389|51tIbWEumlUAZ70JnhDxhTPiPAcLXBlqpQvPXsJrbd5e0c81',\n",
       "   'status': 'documents'},\n",
       "  'id': 'call_MTCP0VYnTuDeM7GUghK5qUmm',\n",
       "  'type': 'tool_call'}]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "msg.tool_calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'__arg1'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m chain\u001b[38;5;241m=\u001b[39mllm_with_tools \u001b[38;5;241m|\u001b[39m (\u001b[38;5;28;01mlambda\u001b[39;00m x: x\u001b[38;5;241m.\u001b[39mtool_calls[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124margs\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__arg1\u001b[39m\u001b[38;5;124m\"\u001b[39m]) \u001b[38;5;241m|\u001b[39m count_sales_by_status\n\u001b[0;32m----> 2\u001b[0m \u001b[43mchain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_data\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/langchain_core/runnables/base.py:2824\u001b[0m, in \u001b[0;36mRunnableSequence.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   2822\u001b[0m             \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m step\u001b[38;5;241m.\u001b[39minvoke(\u001b[38;5;28minput\u001b[39m, config, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   2823\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2824\u001b[0m             \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mstep\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2825\u001b[0m \u001b[38;5;66;03m# finish the root run\u001b[39;00m\n\u001b[1;32m   2826\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/langchain_core/runnables/base.py:4387\u001b[0m, in \u001b[0;36mRunnableLambda.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   4373\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Invoke this Runnable synchronously.\u001b[39;00m\n\u001b[1;32m   4374\u001b[0m \n\u001b[1;32m   4375\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4384\u001b[0m \u001b[38;5;124;03m    TypeError: If the Runnable is a coroutine function.\u001b[39;00m\n\u001b[1;32m   4385\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   4386\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfunc\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m-> 4387\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_with_config\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   4388\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_invoke\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4389\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4390\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_config\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4391\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4392\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4393\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   4394\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m   4395\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot invoke a coroutine function synchronously.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   4396\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUse `ainvoke` instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   4397\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/langchain_core/runnables/base.py:1734\u001b[0m, in \u001b[0;36mRunnable._call_with_config\u001b[0;34m(self, func, input, config, run_type, **kwargs)\u001b[0m\n\u001b[1;32m   1730\u001b[0m     context \u001b[38;5;241m=\u001b[39m copy_context()\n\u001b[1;32m   1731\u001b[0m     context\u001b[38;5;241m.\u001b[39mrun(_set_config_context, child_config)\n\u001b[1;32m   1732\u001b[0m     output \u001b[38;5;241m=\u001b[39m cast(\n\u001b[1;32m   1733\u001b[0m         Output,\n\u001b[0;32m-> 1734\u001b[0m         \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1735\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcall_func_with_variable_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[1;32m   1736\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[1;32m   1737\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[1;32m   1738\u001b[0m \u001b[43m            \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1739\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1740\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1741\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m   1742\u001b[0m     )\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1744\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/langchain_core/runnables/config.py:379\u001b[0m, in \u001b[0;36mcall_func_with_variable_args\u001b[0;34m(func, input, config, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    377\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m run_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m accepts_run_manager(func):\n\u001b[1;32m    378\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m run_manager\n\u001b[0;32m--> 379\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/langchain_core/runnables/base.py:4243\u001b[0m, in \u001b[0;36mRunnableLambda._invoke\u001b[0;34m(self, input, run_manager, config, **kwargs)\u001b[0m\n\u001b[1;32m   4241\u001b[0m                 output \u001b[38;5;241m=\u001b[39m chunk\n\u001b[1;32m   4242\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 4243\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mcall_func_with_variable_args\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   4244\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m   4245\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4246\u001b[0m \u001b[38;5;66;03m# If the output is a Runnable, invoke it\u001b[39;00m\n\u001b[1;32m   4247\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(output, Runnable):\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/langchain_core/runnables/config.py:379\u001b[0m, in \u001b[0;36mcall_func_with_variable_args\u001b[0;34m(func, input, config, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    377\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m run_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m accepts_run_manager(func):\n\u001b[1;32m    378\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m run_manager\n\u001b[0;32m--> 379\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[29], line 1\u001b[0m, in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[0;32m----> 1\u001b[0m chain\u001b[38;5;241m=\u001b[39mllm_with_tools \u001b[38;5;241m|\u001b[39m (\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtool_calls\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43margs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m__arg1\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m) \u001b[38;5;241m|\u001b[39m count_sales_by_status\n\u001b[1;32m      2\u001b[0m chain\u001b[38;5;241m.\u001b[39minvoke(input_data)\n",
      "\u001b[0;31mKeyError\u001b[0m: '__arg1'"
     ]
    }
   ],
   "source": [
    "chain=llm_with_tools | (lambda x: x.tool_calls[0][\"args\"][\"__arg1\"]) | count_sales_by_status\n",
    "chain.invoke(input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructuredTool(name='count_sales_by_status', description='Count the number of sales the user has with a specific status.\\n\\n\\nArgs:\\n    token (str): The authorization token required to access the API.\\n    status (str): The status to filter the API request. Acceptable status by the API: reserved, documents, contract, active, canceled, overdue, finalized, deeded.\\n\\nReturns:\\n    int: The number of sales with the requested status.', args_schema=<class 'pydantic.v1.main.count_sales_by_statusSchema'>, func=<function count_sales_by_status at 0x11cda76d0>)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_sales_by_status"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "008b7d227ee1443b970bfb176cd5b2b5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a12db68ee6dc472eb02dca08c420f9f3",
      "placeholder": "",
      "style": "IPY_MODEL_fae25eac95f0409fa1a75ca8be69147c",
      "value": "tokenizer_config.json:100%"
     }
    },
    "0100d6760bc543afa6059631e937af2f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "029f8e5b75b04fbe9a5ad1658a6557aa": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "032a03aeee124c3e9a9950df4b3ef432": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_dff85f8149674f459b89803fc7153e3e",
      "placeholder": "",
      "style": "IPY_MODEL_464269e3d6ca4c5d8211cf2084d2d17e",
      "value": "349/349[00:00&lt;00:00,23.6kB/s]"
     }
    },
    "035b4ae8f52e4108b7f9954592d69e2c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0ace348c6e3a4100bf2e113d4c41ee86",
      "placeholder": "",
      "style": "IPY_MODEL_e368661e1682492b82023b9cc9a98a99",
      "value": "sentence_bert_config.json:100%"
     }
    },
    "06208b7d09b44c4894d61eea32db0b82": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_19d030715ed44f2cb0aa3c46dcf78156",
      "placeholder": "",
      "style": "IPY_MODEL_67571c30f4da4e9095c5ebe5dd05ac1f",
      "value": "README.md:100%"
     }
    },
    "07bcf47ccd984238a55453d229ba9336": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "084a0038b5ec449297460deec481693c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_fb1bc3b542e742a787ac8cdd8b794600",
       "IPY_MODEL_a37869d5478f4b2f82125c9785b9b436",
       "IPY_MODEL_032a03aeee124c3e9a9950df4b3ef432"
      ],
      "layout": "IPY_MODEL_91bb089964f94d2c94f2bc7533c8e25b"
     }
    },
    "0ace348c6e3a4100bf2e113d4c41ee86": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0d1f76e36d834e65bb7425a7205ee7f7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_029f8e5b75b04fbe9a5ad1658a6557aa",
      "placeholder": "",
      "style": "IPY_MODEL_7a2257fb33e34d69b960d2636cab3b33",
      "value": "tokenizer.json:100%"
     }
    },
    "0ded6b95cb3c40559927e77260caa4c3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_104b82369cd646fe9b04f78ecac6b09c",
      "max": 466021,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_5fe5a6d57e494914987ebf8ca2640d43",
      "value": 466021
     }
    },
    "104b82369cd646fe9b04f78ecac6b09c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "12f6319c71b8490fbf6df0b3bf5ead4d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "145cf50f6cab4b158d2080ce60059ee0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "17725872d9b14c1ca7be6d42f93e2811": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "19d030715ed44f2cb0aa3c46dcf78156": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "19ff658c4aa14f0f8c623bf87552eb47": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_27dd7624edc644e48c7a245c90dbe46c",
      "placeholder": "",
      "style": "IPY_MODEL_67120da8875c492bbfdff8fb995bdb56",
      "value": "10.6k/10.6k[00:00&lt;00:00,654kB/s]"
     }
    },
    "1d0a797258e24930bf8569ceb0ebeab0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_da6cbd2764fa4fc68ae84426725a8625",
      "placeholder": "",
      "style": "IPY_MODEL_927e2ba32d7a4573a19d724dbc87b74a",
      "value": "1_Pooling/config.json:100%"
     }
    },
    "1fedf56b3bba42a589e37c0452797320": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "270990277966485eb20a9ae97c1f376d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "27b01b2b7e704244afdfb95645db9a71": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "27dd7624edc644e48c7a245c90dbe46c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "27e4335a16574eaea7084db58ff7ea3f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "286ee328f3ca44a583e4a6e17a7a9a22": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2ab25e703d944cf6bd57d23dddbee25c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "2c8197a5208b46e8a7be9eb622f61c93": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "2dc45170227d47e08fdcc4b7cf4b20c0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "367d9496c40542818869ca70c201776c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "39e9f2d982c54eb39f62927deeda57c4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_17725872d9b14c1ca7be6d42f93e2811",
      "placeholder": "",
      "style": "IPY_MODEL_e1b1425d29c046149b5b7dd43e17b45b",
      "value": "363/363[00:00&lt;00:00,22.9kB/s]"
     }
    },
    "3acd5c289e2b4839b92a99457c0197a3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "417145bfcaa846d2b5242bce340e714d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_07bcf47ccd984238a55453d229ba9336",
      "max": 437971872,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_69ff32abfb1d49b58a04519d9e445e02",
      "value": 437971872
     }
    },
    "43b529058903409d99e81f4a33b491f5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "44a8073da9cd40a588a02c3df2de2665": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "464269e3d6ca4c5d8211cf2084d2d17e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "464872045ebc41cdacd5cf89ac591bd6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "478a39d31ab54a9eb58a7279d174eecb": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "48bb0a3f7c2c4bc285b6763313eda159": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_27e4335a16574eaea7084db58ff7ea3f",
      "max": 190,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_ac06bdf136ba40da933ba9fbdaeb72d9",
      "value": 190
     }
    },
    "49b9303aff0a4d26a7897850223221b3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "550af51366264da6bc279e67ad82f94d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5b5c2b418af04548ab93918fb26c1620": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_550af51366264da6bc279e67ad82f94d",
      "max": 239,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_e246a6a64a774aaa8de93ae6dc7ae96c",
      "value": 239
     }
    },
    "5b9bb6dddff44a64aed0c4bb9238f551": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b69bdda9bec24b22a027d77565130704",
      "max": 571,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_270990277966485eb20a9ae97c1f376d",
      "value": 571
     }
    },
    "5bbcba16869042f795f0e78d3cd5e39e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d521a1a4b35a4a2eba84c37fb376b7ad",
      "placeholder": "",
      "style": "IPY_MODEL_d2a49bef5cf24039b7a9e62b1642c1b3",
      "value": "239/239[00:00&lt;00:00,9.46kB/s]"
     }
    },
    "5fe0f3049c794d1881a1336dbff1bcd0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5fe5a6d57e494914987ebf8ca2640d43": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "61691b5d18fc44ecacda46b88f874cc4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "67120da8875c492bbfdff8fb995bdb56": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "67571c30f4da4e9095c5ebe5dd05ac1f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "69ff32abfb1d49b58a04519d9e445e02": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "6b74b2095f564ac78f26ead3ec868d4d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a8f60727d06645bbb2f623ebd2db114a",
      "placeholder": "",
      "style": "IPY_MODEL_dbb5c0fd46194d0594d385e8d60cccb3",
      "value": "config_sentence_transformers.json:100%"
     }
    },
    "6bd138a3e01640e997810f9b71264c47": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_06208b7d09b44c4894d61eea32db0b82",
       "IPY_MODEL_ebbd4cbedf664d168116b13629478f4c",
       "IPY_MODEL_19ff658c4aa14f0f8c623bf87552eb47"
      ],
      "layout": "IPY_MODEL_9c184e70490e4f4b8e620774736de029"
     }
    },
    "6c3e6d030a1a4993a812e128cd1cb56d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_27b01b2b7e704244afdfb95645db9a71",
      "placeholder": "",
      "style": "IPY_MODEL_ebf599bae0a64054ae1314c4b1469701",
      "value": "116/116[00:00&lt;00:00,7.28kB/s]"
     }
    },
    "6ed5b15e9cb64600a0a33ac01eb2a656": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_286ee328f3ca44a583e4a6e17a7a9a22",
      "placeholder": "",
      "style": "IPY_MODEL_1fedf56b3bba42a589e37c0452797320",
      "value": "190/190[00:00&lt;00:00,6.88kB/s]"
     }
    },
    "73475bbb3fd949ab9ce9cffb4e6157a2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7619b5e38a83414b81c27d924571581b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "76c33f0733aa41cf9a00a417867dd2f2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_145cf50f6cab4b158d2080ce60059ee0",
      "placeholder": "",
      "style": "IPY_MODEL_bfaa0777dc214b45843bf9ec431b3748",
      "value": "config.json:100%"
     }
    },
    "79a3336be19b4d6988cf784c89b119d8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b4dc1fb6b1dc45139f921563edeea9c7",
      "max": 231536,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_f89db308102e40439188ab6500709be5",
      "value": 231536
     }
    },
    "7a2257fb33e34d69b960d2636cab3b33": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "7ceadc92017d401496635b5b281c925e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "83d97561ad2844f6a44ecdb5099cc1e9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "87445bf1b2654d06aae01ac0ed454ad9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "879cd0a6d3014bb9805bbdbfe8794487": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "892b052e040b4e318f05812d82691d46": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_367d9496c40542818869ca70c201776c",
      "placeholder": "",
      "style": "IPY_MODEL_a9eeab3b052b466a9f62e9ae6b4b91a6",
      "value": "53.0/53.0[00:00&lt;00:00,2.74kB/s]"
     }
    },
    "898e547bb7b9493c99c2ecbec75146bc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_0d1f76e36d834e65bb7425a7205ee7f7",
       "IPY_MODEL_0ded6b95cb3c40559927e77260caa4c3",
       "IPY_MODEL_cc52b15aa02b488085adbb45bed5a43f"
      ],
      "layout": "IPY_MODEL_dcd017f5203640488bffc293dfa061c6"
     }
    },
    "8a77b322c3e44307821d9fded2e3c25c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "8bedbdf27f4a444489a9941ca9c9c4a3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e7889bf0482d485c9c2bfd48ce12e666",
      "max": 363,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_2ab25e703d944cf6bd57d23dddbee25c",
      "value": 363
     }
    },
    "8d370ca4226f436dae3c5e85549ad5f7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "91bb089964f94d2c94f2bc7533c8e25b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "927e2ba32d7a4573a19d724dbc87b74a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "99bc5473f32c48cab946c7a6033b6c2a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9c184e70490e4f4b8e620774736de029": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a0c615986d944a9cb60836ab3ba3f563": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_478a39d31ab54a9eb58a7279d174eecb",
      "placeholder": "",
      "style": "IPY_MODEL_e5d9f0e7a8bf4629958b30d36efeb0cd",
      "value": "438M/438M[00:03&lt;00:00,147MB/s]"
     }
    },
    "a12db68ee6dc472eb02dca08c420f9f3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a30d8a3c02c940c69aaeaf9cc5d46848": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_008b7d227ee1443b970bfb176cd5b2b5",
       "IPY_MODEL_8bedbdf27f4a444489a9941ca9c9c4a3",
       "IPY_MODEL_39e9f2d982c54eb39f62927deeda57c4"
      ],
      "layout": "IPY_MODEL_a8b807b24ab6455faf60499936d126d5"
     }
    },
    "a37869d5478f4b2f82125c9785b9b436": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_61691b5d18fc44ecacda46b88f874cc4",
      "max": 349,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_d9c4e126c8b14f5e9ce4303fcaa54e09",
      "value": 349
     }
    },
    "a8b807b24ab6455faf60499936d126d5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a8f60727d06645bbb2f623ebd2db114a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a974d3f931ca48c8bcab79b4d639cb76": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_76c33f0733aa41cf9a00a417867dd2f2",
       "IPY_MODEL_5b9bb6dddff44a64aed0c4bb9238f551",
       "IPY_MODEL_eb824d8ec7b44726af215fdc8be40813"
      ],
      "layout": "IPY_MODEL_99bc5473f32c48cab946c7a6033b6c2a"
     }
    },
    "a9eeab3b052b466a9f62e9ae6b4b91a6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "aac2173b7cda4fcfa9e99a630aeb29ac": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ac06bdf136ba40da933ba9fbdaeb72d9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "ae04ebe295e34373b74faf3ec1bb2cfa": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_87445bf1b2654d06aae01ac0ed454ad9",
      "max": 116,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_f79fc34cf7914438a17fc10e8185bf10",
      "value": 116
     }
    },
    "aeda4b1d6ac246e686813fbee185d39b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3acd5c289e2b4839b92a99457c0197a3",
      "placeholder": "",
      "style": "IPY_MODEL_49b9303aff0a4d26a7897850223221b3",
      "value": "special_tokens_map.json:100%"
     }
    },
    "b4dc1fb6b1dc45139f921563edeea9c7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b69bdda9bec24b22a027d77565130704": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bfaa0777dc214b45843bf9ec431b3748": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c616faf23fa14d598d8fd15cc2866d58": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "cb23c3e448494d6c91cc15a0d4b6dbbc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f5ed01e00cf04185871747df0826cb16",
      "placeholder": "",
      "style": "IPY_MODEL_5fe0f3049c794d1881a1336dbff1bcd0",
      "value": "model.safetensors:100%"
     }
    },
    "cbe03d7dda4f4912b8db418e14f444f2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_aeda4b1d6ac246e686813fbee185d39b",
       "IPY_MODEL_5b5c2b418af04548ab93918fb26c1620",
       "IPY_MODEL_5bbcba16869042f795f0e78d3cd5e39e"
      ],
      "layout": "IPY_MODEL_464872045ebc41cdacd5cf89ac591bd6"
     }
    },
    "cc52b15aa02b488085adbb45bed5a43f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d023080eec2547029bf38facff69a6b9",
      "placeholder": "",
      "style": "IPY_MODEL_c616faf23fa14d598d8fd15cc2866d58",
      "value": "466k/466k[00:00&lt;00:00,3.75MB/s]"
     }
    },
    "d0084d02f18d4f8d881f8681b7660e3a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d023080eec2547029bf38facff69a6b9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d2a49bef5cf24039b7a9e62b1642c1b3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d521a1a4b35a4a2eba84c37fb376b7ad": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d9c4e126c8b14f5e9ce4303fcaa54e09": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "da6cbd2764fa4fc68ae84426725a8625": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "db8cf6a511c84896940e7e7a03d5a866": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7ceadc92017d401496635b5b281c925e",
      "placeholder": "",
      "style": "IPY_MODEL_879cd0a6d3014bb9805bbdbfe8794487",
      "value": "vocab.txt:100%"
     }
    },
    "dbb5c0fd46194d0594d385e8d60cccb3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "dcd017f5203640488bffc293dfa061c6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "df213338b072434aa2ced9908d0ba3c0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "dff85f8149674f459b89803fc7153e3e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e1b1425d29c046149b5b7dd43e17b45b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e20c8adfc1ea448ea770b476a0b8e1a4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_db8cf6a511c84896940e7e7a03d5a866",
       "IPY_MODEL_79a3336be19b4d6988cf784c89b119d8",
       "IPY_MODEL_fbb977bfbbe149858563e29a346380fe"
      ],
      "layout": "IPY_MODEL_f8e39202a22a4f01bacc6d16efc180e2"
     }
    },
    "e246a6a64a774aaa8de93ae6dc7ae96c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "e368661e1682492b82023b9cc9a98a99": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e5d9f0e7a8bf4629958b30d36efeb0cd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e6b3b724429b47869397453137a0faca": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_cb23c3e448494d6c91cc15a0d4b6dbbc",
       "IPY_MODEL_417145bfcaa846d2b5242bce340e714d",
       "IPY_MODEL_a0c615986d944a9cb60836ab3ba3f563"
      ],
      "layout": "IPY_MODEL_73475bbb3fd949ab9ce9cffb4e6157a2"
     }
    },
    "e7889bf0482d485c9c2bfd48ce12e666": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "eb824d8ec7b44726af215fdc8be40813": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_44a8073da9cd40a588a02c3df2de2665",
      "placeholder": "",
      "style": "IPY_MODEL_8a77b322c3e44307821d9fded2e3c25c",
      "value": "571/571[00:00&lt;00:00,28.8kB/s]"
     }
    },
    "ebbd4cbedf664d168116b13629478f4c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_83d97561ad2844f6a44ecdb5099cc1e9",
      "max": 10621,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_2c8197a5208b46e8a7be9eb622f61c93",
      "value": 10621
     }
    },
    "ebf599bae0a64054ae1314c4b1469701": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "eddd05e7269c41af98b12f260425e834": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_035b4ae8f52e4108b7f9954592d69e2c",
       "IPY_MODEL_fcb9ac37f7dc4ec2992275c805a86b4b",
       "IPY_MODEL_892b052e040b4e318f05812d82691d46"
      ],
      "layout": "IPY_MODEL_0100d6760bc543afa6059631e937af2f"
     }
    },
    "ef324189b1844b15b711bca7f023007c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_1d0a797258e24930bf8569ceb0ebeab0",
       "IPY_MODEL_48bb0a3f7c2c4bc285b6763313eda159",
       "IPY_MODEL_6ed5b15e9cb64600a0a33ac01eb2a656"
      ],
      "layout": "IPY_MODEL_7619b5e38a83414b81c27d924571581b"
     }
    },
    "f5ed01e00cf04185871747df0826cb16": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f79fc34cf7914438a17fc10e8185bf10": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "f89db308102e40439188ab6500709be5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "f8e39202a22a4f01bacc6d16efc180e2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fae25eac95f0409fa1a75ca8be69147c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "fb1bc3b542e742a787ac8cdd8b794600": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_aac2173b7cda4fcfa9e99a630aeb29ac",
      "placeholder": "",
      "style": "IPY_MODEL_2dc45170227d47e08fdcc4b7cf4b20c0",
      "value": "modules.json:100%"
     }
    },
    "fbb977bfbbe149858563e29a346380fe": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d0084d02f18d4f8d881f8681b7660e3a",
      "placeholder": "",
      "style": "IPY_MODEL_df213338b072434aa2ced9908d0ba3c0",
      "value": "232k/232k[00:00&lt;00:00,1.84MB/s]"
     }
    },
    "fcb9ac37f7dc4ec2992275c805a86b4b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8d370ca4226f436dae3c5e85549ad5f7",
      "max": 53,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_12f6319c71b8490fbf6df0b3bf5ead4d",
      "value": 53
     }
    },
    "fd07a7b9f1b1409ebd3f660f0518e758": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_6b74b2095f564ac78f26ead3ec868d4d",
       "IPY_MODEL_ae04ebe295e34373b74faf3ec1bb2cfa",
       "IPY_MODEL_6c3e6d030a1a4993a812e128cd1cb56d"
      ],
      "layout": "IPY_MODEL_43b529058903409d99e81f4a33b491f5"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
